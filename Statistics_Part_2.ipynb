{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Part 2"
      ],
      "metadata": {
        "id": "Q7JQIg1k0mno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics ?\n",
        "\n",
        "- Hypothesis testing in statistics is a method used to decide whether there is enough evidence to support a specific claim (hypothesis) about a population, based on sample data. It involves:\n",
        "\n",
        "1. **Null hypothesis (H‚ÇÄ):** The default assumption (e.g., no effect or no difference).\n",
        "2. **Alternative hypothesis (H‚ÇÅ):** What you want to test (e.g., there is an effect).\n",
        "3. **P-value:** Probability of observing the data if H‚ÇÄ is true.\n",
        "4. **Decision:** If the p-value is less than the significance level (e.g., 0.05), reject H‚ÇÄ.\n",
        "\n",
        "In short, it's a way to test assumptions using data.\n",
        "\n",
        "----\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis ?\n",
        "\n",
        "- The **null hypothesis (H‚ÇÄ)** is the assumption that there is no effect or no difference. The **alternative hypothesis (H‚ÇÅ or Ha)** is the claim that there **is** an effect or a difference.\n",
        "\n",
        "**Difference:**  \n",
        "- H‚ÇÄ: Status quo or default (e.g., mean = 50)  \n",
        "- H‚ÇÅ: What you're trying to prove (e.g., mean ‚â† 50)\n",
        "\n",
        "We test data to decide whether to reject H‚ÇÄ in favor of H‚ÇÅ.\n",
        "\n",
        "----\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important ?\n",
        "\n",
        "- The **significance level** (denoted as **Œ±**) is the probability of rejecting the null hypothesis when it is actually true ‚Äî also called the **risk of a false positive**.\n",
        "\n",
        "Common values: **0.05**, **0.01**, or **0.10**.\n",
        "\n",
        "**Why it's important:**  \n",
        "It sets the **threshold** for how much evidence is needed to reject the null hypothesis. A lower Œ± means stricter evidence is required, reducing the chance of a false claim.\n",
        "\n",
        "-----\n",
        "4. What does a P-value represent in hypothesis testing ?\n",
        "- A **p-value** is the probability of getting results as extreme as (or more extreme than) the observed data, **assuming the null hypothesis is true**.\n",
        "\n",
        "**In simple terms:**  \n",
        "It tells us how likely our results are due to chance.\n",
        "\n",
        "- **Low p-value (‚â§ Œ±):** Strong evidence against H‚ÇÄ ‚Üí reject H‚ÇÄ  \n",
        "- **High p-value (> Œ±):** Weak evidence against H‚ÇÄ ‚Üí fail to reject H‚ÇÄ\n",
        "\n",
        "It helps decide whether the results are statistically significant.\n",
        "\n",
        "----\n",
        "5. How do you interpret the P-value in hypothesis testing ?\n",
        "\n",
        "- **Interpreting the p-value:**\n",
        "\n",
        "- **If p-value ‚â§ significance level (Œ±):**  \n",
        "  ‚Üí Reject the null hypothesis (H‚ÇÄ).  \n",
        "  ‚Üí The result is **statistically significant** (unlikely due to chance).\n",
        "\n",
        "- **If p-value > significance level (Œ±):**  \n",
        "  ‚Üí Fail to reject the null hypothesis.  \n",
        "  ‚Üí The result is **not statistically significant** (could be due to chance).\n",
        "\n",
        "**Example:**  \n",
        "If Œ± = 0.05 and p = 0.03 ‚Üí reject H‚ÇÄ (significant result).  \n",
        "If p = 0.08 ‚Üí do not reject H‚ÇÄ (not significant).\n",
        "\n",
        "----\n",
        "6.  What are Type 1 and Type 2 errors in hypothesis testing ?\n",
        "- In hypothesis testing:\n",
        "\n",
        "- **Type I Error (False Positive):**  \n",
        "  Rejecting the **null hypothesis (H‚ÇÄ)** when it is actually **true**.  \n",
        "  - Probability = **Œ±** (significance level)\n",
        "\n",
        "- **Type II Error (False Negative):**  \n",
        "  Failing to reject the **null hypothesis** when the **alternative hypothesis (H‚ÇÅ)** is actually **true**.  \n",
        "  - Probability = **Œ≤**\n",
        "\n",
        "**Simple example:**  \n",
        "- Type I: Saying a drug works when it actually doesn't.  \n",
        "- Type II: Saying a drug doesn't work when it actually does.\n",
        "\n",
        "----\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing ?\n",
        "\n",
        "- **One-tailed test:**  \n",
        "- Tests for an effect in **one specific direction** (e.g., greater than or less than).  \n",
        "- Example: H‚ÇÅ: mean > 50\n",
        "\n",
        "**Two-tailed test:**  \n",
        "- Tests for an effect in **either direction** (e.g., not equal).  \n",
        "- Example: H‚ÇÅ: mean ‚â† 50\n",
        "\n",
        "**Key difference:**  \n",
        "- **One-tailed** looks for an effect on **one side** of the distribution.  \n",
        "- **Two-tailed** looks for an effect on **both sides**.\n",
        "\n",
        "----\n",
        "8. What is the Z-test, and when is it used in hypothesis testing ?\n",
        "- The **Z-test** is a statistical test used to determine whether there is a significant difference between sample and population means (or between two sample means), **when the population standard deviation is known** and the sample size is large (n ‚â• 30).\n",
        "\n",
        "**When to use it:**\n",
        "- Population standard deviation (œÉ) is known  \n",
        "- Sample size is large  \n",
        "- Data is approximately normally distributed\n",
        "\n",
        "**Examples:**\n",
        "- Testing if a sample mean differs from a known population mean  \n",
        "- Comparing two means when variances are known and large samples are used\n",
        "\n",
        "-----\n",
        "9.  How do you calculate the Z-score, and what does it represent in hypothesis testing ?\n",
        "- **Z-score formula (for a sample mean):**  \n",
        "\\[\n",
        "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( \\bar{X} \\) = sample mean  \n",
        "- \\( \\mu \\) = population mean  \n",
        "- \\( \\sigma \\) = population standard deviation  \n",
        "- \\( n \\) = sample size\n",
        "\n",
        "**What it represents:**  \n",
        "The **Z-score** tells you how many **standard deviations** the sample mean is from the population mean.  \n",
        "\n",
        "In hypothesis testing, it helps determine how unusual the sample result is under the null hypothesis ‚Äî and is used to find the **p-value**.\n",
        "----\n",
        "\n",
        "10.  What is the T-distribution, and when should it be used instead of the normal distribution ?\n",
        "- The **T-distribution** is a probability distribution used in statistics when estimating population parameters **with small sample sizes** and/or when the **population standard deviation is unknown**.\n",
        "\n",
        "### Use the **T-distribution** when:\n",
        "- Sample size is **small** (typically **n < 30**)  \n",
        "- **Population standard deviation (œÉ)** is **unknown**  \n",
        "- Data is approximately **normally distributed**\n",
        "\n",
        "### Why it's used:\n",
        "The T-distribution is **wider and has heavier tails** than the normal distribution, which accounts for extra uncertainty in small samples.\n",
        "\n",
        "As sample size increases, the T-distribution becomes more like the **normal distribution**.\n",
        "\n",
        "------\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test ?\n",
        "\n",
        "- **Z-test vs. T-test:**\n",
        "\n",
        "| Feature              | **Z-test**                                     | **T-test**                                      |\n",
        "|----------------------|------------------------------------------------|-------------------------------------------------|\n",
        "| **Population SD known?** | Yes                                            | No                                              |\n",
        "| **Sample size**      | Large (n ‚â• 30)                                | Small (n < 30)                                  |\n",
        "| **Distribution used**| Normal distribution                           | T-distribution                                  |\n",
        "| **Use case**         | Comparing means when population SD is known   | Comparing means when population SD is unknown   |\n",
        "\n",
        "**In short:**  \n",
        "- Use **Z-test** when the sample is large **and** œÉ is known.  \n",
        "- Use **T-test** when the sample is small **or** œÉ is unknown.\n",
        "\n",
        "-----\n",
        "12. What is the T-test, and how is it used in hypothesis testing ?\n",
        "- The **T-test** is a statistical test used to compare means and determine if the difference between them is **statistically significant**, especially when the **population standard deviation is unknown**.\n",
        "\n",
        "### **Types of T-tests:**\n",
        "1. **One-sample T-test:**  \n",
        "   Tests if the sample mean differs from a known value.\n",
        "2. **Two-sample (independent) T-test:**  \n",
        "   Compares means from two independent groups.\n",
        "3. **Paired T-test:**  \n",
        "   Compares means from the same group at different times.\n",
        "\n",
        "### **How it's used:**\n",
        "- Set up null (H‚ÇÄ) and alternative (H‚ÇÅ) hypotheses  \n",
        "- Calculate the **t-statistic**  \n",
        "- Compare with critical value or use the **p-value**  \n",
        "- Make a decision: reject or fail to reject H‚ÇÄ\n",
        "\n",
        "It‚Äôs especially useful for small sample sizes and unknown population standard deviations.\n",
        "----\n",
        "\n",
        "13.  What is the relationship between Z-test and T-test in hypothesis testing ?\n",
        "\n",
        "- The **Z-test and T-test** are both used in hypothesis testing to compare means, but they differ mainly in terms of **sample size** and **known vs. unknown population standard deviation**.\n",
        "\n",
        "### **Relationship:**\n",
        "\n",
        "- Both tests check if a sample mean significantly differs from a population mean or another sample mean.\n",
        "- Both follow a similar structure (test statistic, p-value, decision).\n",
        "- The **T-test becomes similar to the Z-test** as the **sample size increases** ‚Äî because the **T-distribution approaches the normal distribution**.\n",
        "\n",
        "### **Key Difference:**\n",
        "\n",
        "| Condition                 | Use Z-test       | Use T-test       |\n",
        "|--------------------------|------------------|------------------|\n",
        "| Population SD known      | ‚úÖ Yes            | ‚ùå No             |\n",
        "| Sample size large (n ‚â• 30)| ‚úÖ Preferred      | ‚úÖ Can be used    |\n",
        "| Sample size small (n < 30)| ‚ùå Not ideal      | ‚úÖ Required       |\n",
        "\n",
        "**In short:**  \n",
        "The T-test is a generalization of the Z-test used when there's more uncertainty (like small samples or unknown SD).\n",
        "\n",
        "----\n",
        "\n",
        "14.  What is a confidence interval, and how is it used to interpret statistical results ?\n",
        "- A **confidence interval (CI)** is a range of values that is likely to contain the true population parameter (like a mean or proportion) with a certain level of confidence.\n",
        "\n",
        "### Example:\n",
        "A 95% confidence interval means **we are 95% confident** that the true value lies within that range.\n",
        "\n",
        "### How it's used:\n",
        "- **Estimates uncertainty** in sample results  \n",
        "- **Narrow CI** = more precise estimate  \n",
        "- If the **CI does not include the null hypothesis value** (e.g., mean = 0), the result is **statistically significant**\n",
        "\n",
        "### In short:\n",
        "A confidence interval helps interpret results by showing a likely range for the true value and whether the result is significant.\n",
        "\n",
        "-----\n",
        "15. What is the margin of error, and how does it affect the confidence interval ?\n",
        "- The **margin of error (MoE)** is the amount added and subtracted from the sample estimate to create a **confidence interval**. It reflects the **uncertainty** in the estimate due to sampling.\n",
        "\n",
        "### Formula (basic):\n",
        "\\[\n",
        "\\text{Margin of Error} = z^* \\times \\frac{\\sigma}{\\sqrt{n}}\n",
        "\\]\n",
        "Where:\n",
        "- \\( z^* \\) = critical value (based on confidence level)\n",
        "- \\( \\sigma \\) = standard deviation\n",
        "- \\( n \\) = sample size\n",
        "\n",
        "### **How it affects the confidence interval:**\n",
        "\\[\n",
        "\\text{Confidence Interval} = \\text{Sample Estimate} \\pm \\text{Margin of Error}\n",
        "\\]\n",
        "\n",
        "### Key points:\n",
        "- **Larger MoE ‚Üí wider confidence interval** ‚Üí less precision  \n",
        "- **Smaller MoE ‚Üí narrower interval** ‚Üí more precision  \n",
        "- MoE decreases with **larger sample sizes** or **lower confidence levels**\n",
        "\n",
        "**In short:**  \n",
        "Margin of error controls the **width** of the confidence interval and reflects the level of uncertainty in the estimate.\n",
        "-----\n",
        "\n",
        "16.  How is Bayes' Theorem used in statistics, and what is its significance ?\n",
        "\n",
        "- **Bayes' Theorem** is used in statistics to **update the probability** of a hypothesis based on **new evidence or data**.\n",
        "\n",
        "### **Formula:**\n",
        "\\[\n",
        "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( P(A|B) \\): Posterior probability (probability of A given B)  \n",
        "- \\( P(B|A) \\): Likelihood (probability of B given A)  \n",
        "- \\( P(A) \\): Prior probability (initial belief about A)  \n",
        "- \\( P(B) \\): Total probability of B\n",
        "\n",
        "### **How it's used:**\n",
        "- In **medical testing** (e.g., chance of disease given a positive test)  \n",
        "- In **machine learning** (e.g., spam filters, classification)  \n",
        "- In **decision making under uncertainty**\n",
        "\n",
        "### **Significance:**\n",
        "Bayes' Theorem allows combining **prior knowledge** with **new data**, making it a powerful tool for **probabilistic reasoning** and **updating beliefs**.\n",
        "\n",
        "-----\n",
        "\n",
        "17.  What is the Chi-square distribution, and when is it used ?\n",
        "- The **Chi-square (œá¬≤) distribution** is a statistical distribution used to test relationships between categorical variables and to assess the **goodness of fit** or **independence** in a dataset.\n",
        "\n",
        "### **When it's used:**\n",
        "\n",
        "1. **Chi-square test of independence:**  \n",
        "   - To check if two categorical variables are related.  \n",
        "   - Example: Is gender related to voting preference?\n",
        "\n",
        "2. **Chi-square goodness-of-fit test:**  \n",
        "   - To see if sample data fits an expected distribution.  \n",
        "   - Example: Do dice rolls follow a uniform distribution?\n",
        "\n",
        "### **Key features:**\n",
        "- Only takes **non-negative** values (starts at 0)  \n",
        "- **Asymmetrical** and **right-skewed**  \n",
        "- Shape depends on **degrees of freedom (df)**\n",
        "\n",
        "### **In short:**  \n",
        "The Chi-square distribution is used to test hypotheses about **categorical data** ‚Äî mainly to check for **association** or how well observed data fits expected values.\n",
        "\n",
        "----\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied ?\n",
        "- The **Chi-square goodness of fit test** is used to determine whether a set of **observed frequencies** matches **expected frequencies** for a categorical variable.\n",
        "\n",
        "### **Purpose:**  \n",
        "To test if the data follows a specific distribution.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps to apply it:**\n",
        "\n",
        "1. **State hypotheses:**  \n",
        "   - **H‚ÇÄ (null):** Observed data fits the expected distribution  \n",
        "   - **H‚ÇÅ (alternative):** Observed data does **not** fit the expected distribution\n",
        "\n",
        "2. **Calculate expected frequencies** based on the assumed distribution.\n",
        "\n",
        "3. **Compute test statistic:**  \n",
        "   \\[\n",
        "   \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
        "   \\]  \n",
        "   Where:\n",
        "   - \\( O_i \\) = observed frequency  \n",
        "   - \\( E_i \\) = expected frequency\n",
        "\n",
        "4. **Compare** the result to a critical value from the **Chi-square distribution table** (based on degrees of freedom and significance level), or find the **p-value**.\n",
        "\n",
        "5. **Decision:**  \n",
        "   - If \\( \\chi^2 \\) is large or p-value < Œ± ‚Üí reject H‚ÇÄ  \n",
        "   - Otherwise ‚Üí fail to reject H‚ÇÄ\n",
        "\n",
        "---\n",
        "\n",
        "### **Example use:**  \n",
        "You roll a die 60 times. If each face should appear 10 times (uniform distribution), the test checks whether your actual results significantly differ from that expectation.\n",
        "\n",
        "----\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing ?\n",
        "- The **F-distribution** is a probability distribution used mainly to compare **variances** between two groups. It is **right-skewed** and only takes **positive values**.\n",
        "\n",
        "---\n",
        "\n",
        "### **When it is used in hypothesis testing:**\n",
        "\n",
        "1. **ANOVA (Analysis of Variance):**  \n",
        "   - To test if **three or more group means** are significantly different.\n",
        "\n",
        "2. **Test of Equal Variances:**  \n",
        "   - To compare the **variability** (variance) of two populations.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key features:**\n",
        "- Depends on **two degrees of freedom** (one for numerator, one for denominator)\n",
        "- The larger the F-value, the more likely you‚Äôll reject the null hypothesis\n",
        "\n",
        "---\n",
        "\n",
        "### **In short:**  \n",
        "The **F-distribution** is used when testing hypotheses about **ratios of variances**, especially in **ANOVA** and **variance comparison** problems.\n",
        "\n",
        "----\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions ?\n",
        "- The **ANOVA (Analysis of Variance)** test is a statistical method used to determine if there are **significant differences between the means of three or more groups**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Purpose:**\n",
        "To test the null hypothesis (**H‚ÇÄ**) that **all group means are equal**, against the alternative (**H‚ÇÅ**) that **at least one mean is different**.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Assumptions of ANOVA:**\n",
        "\n",
        "1. **Independence**:  \n",
        "   Observations are independent within and across groups.\n",
        "\n",
        "2. **Normality**:  \n",
        "   The data in each group should be approximately normally distributed.\n",
        "\n",
        "3. **Homogeneity of variances** (equal variances):  \n",
        "   The variances across groups should be roughly equal.\n",
        "\n",
        "---\n",
        "\n",
        "### üí° **In short:**  \n",
        "ANOVA tests if **group differences** are real or just due to **random variation**, and it's valid only if its key assumptions are met.\n",
        "\n",
        "----\n",
        "\n",
        "21.  What are the different types of ANOVA tests ?\n",
        "- There are **three main types of ANOVA** tests, each used for different experimental designs:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **One-Way ANOVA**\n",
        "- **Purpose:** Compares the means of **3 or more independent groups** based on **one factor** (independent variable).\n",
        "- **Example:** Comparing test scores across 3 different teaching methods.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Two-Way ANOVA**\n",
        "- **Purpose:** Compares the means across groups based on **two factors** and can test for:\n",
        "  - Main effects of each factor  \n",
        "  - Interaction effect between the two factors\n",
        "- **Example:** Studying the effect of **teaching method** and **study time** on test scores.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Repeated Measures ANOVA**\n",
        "- **Purpose:** Used when the **same subjects** are measured multiple times (within-subjects design).\n",
        "- **Example:** Measuring blood pressure in the same group of patients **before**, **during**, and **after** treatment.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ Summary:\n",
        "\n",
        "| Type                   | Factors | Groups | Repeated Measures? |\n",
        "|------------------------|---------|--------|---------------------|\n",
        "| **One-Way ANOVA**       | 1       | ‚â•3     | No                  |\n",
        "| **Two-Way ANOVA**       | 2       | ‚â•3     | No (can be extended)|\n",
        "| **Repeated Measures ANOVA** | 1+      | ‚â•3     | Yes                 |\n",
        "\n",
        "Each type helps analyze different kinds of data and research questions.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "22.  What is the F-test, and how does it relate to hypothesis testing ?\n",
        "- The **F-test** is a statistical test used to **compare variances** between two or more groups. It plays a key role in **hypothesis testing**, especially in tests involving multiple groups or models.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Purpose in Hypothesis Testing:**\n",
        "To test whether:\n",
        "- Two populations have **equal variances**  \n",
        "- Group means are **significantly different** (in **ANOVA**)  \n",
        "- A more complex model fits the data better than a simpler one (in **regression**)\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Key Idea:**\n",
        "The **F-statistic** is the ratio of two variances:\n",
        "\\[\n",
        "F = \\frac{\\text{Variance between groups}}{\\text{Variance within groups}}\n",
        "\\]\n",
        "\n",
        "A **high F-value** suggests a significant difference between group means or variances.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó **Relation to Hypothesis Testing:**\n",
        "\n",
        "- **Null hypothesis (H‚ÇÄ):** No difference in variances or means (e.g., all group means are equal)\n",
        "- **Alternative hypothesis (H‚ÇÅ):** At least one variance or mean differs\n",
        "- Compare the F-value to a critical value from the **F-distribution**, or use the **p-value**\n",
        "\n",
        "---\n",
        "\n",
        "### üí° In short:  \n",
        "The **F-test** helps determine if differences between groups are **statistically significant**, and it's central to tests like **ANOVA** and **regression model comparisons**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hl9wK3oS0n9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "VWfjusjI5f6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results .\n",
        "\n",
        "- Sure! Here's a simple Python program that performs a one-sample Z-test to compare a sample mean to a known population mean, along with a basic interpretation of the results."
      ],
      "metadata": {
        "id": "ZawDkJKJ5nvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data\n",
        "sample_data = [52, 48, 51, 53, 47, 50, 49, 52, 46, 54]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Known population parameters\n",
        "population_mean = 50  # Œº\n",
        "population_std = 2    # œÉ\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret result\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "YAqVzfzv7U--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python .\n",
        "- Simulates random sample data from a normal distribution\n",
        "- Performs a one-sample t-test\n",
        "- Calculates the p-value and interprets the result"
      ],
      "metadata": {
        "id": "LRTqxc7k7YMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Step 1: Simulate random data (e.g., test scores with mean ~72)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_data = np.random.normal(loc=72, scale=10, size=30)  # mean=72, std=10, n=30\n",
        "\n",
        "# Step 2: Set population mean to test against (e.g., Œº = 70)\n",
        "population_mean = 70\n",
        "\n",
        "# Step 3: Perform one-sample t-test\n",
        "t_stat, p_value = ttest_1samp(sample_data, population_mean)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(f\"Sample Mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "hGqOcK5484lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean .\n",
        "\n",
        "# Python Code: One-Sample Z-Test"
      ],
      "metadata": {
        "id": "XWqUfg4b87n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data (can be replaced with any data)\n",
        "sample_data = [105, 98, 110, 102, 100, 108, 103, 97, 101, 106]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 100  # Œº (hypothesized mean)\n",
        "population_std = 5     # œÉ (known population standard deviation)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Decision based on significance level\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "RGqYzue09KAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Perform a two-tailed Z-test using Python and visualize the decision region on a plot .\n",
        "- The normal distribution curve\n",
        "\n",
        "- The critical regions\n",
        "\n",
        "- The Z-score of your sample\n",
        "\n",
        "# Python Code: Two-Tailed Z-Test with Visualization"
      ],
      "metadata": {
        "id": "vyulJQZN9R8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data\n",
        "sample_data = [105, 98, 110, 102, 100, 108, 103, 97, 101, 106]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 100   # Œº\n",
        "population_std = 5      # œÉ (known)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Critical z-value for 95% confidence level (Œ± = 0.05)\n",
        "z_critical = norm.ppf(1 - 0.05 / 2)\n",
        "\n",
        "# Display results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(\"Decision:\", \"Reject H‚ÇÄ\" if abs(z_score) > z_critical else \"Fail to reject H‚ÇÄ\")\n",
        "\n",
        "# ---- Visualization ----\n",
        "\n",
        "# Plot settings\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, label='Standard Normal Distribution', color='blue')\n",
        "\n",
        "# Shade critical regions\n",
        "plt.fill_between(x, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.3, label='Rejection Region (Œ± = 0.05)')\n",
        "plt.axvline(z_score, color='green', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "# Annotations\n",
        "plt.title('Two-Tailed Z-Test with Rejection Regions')\n",
        "plt.xlabel('Z')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e2TJqFX_9gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing .\n",
        "- Calculates Type I (Œ±) and Type II (Œ≤) errors\n",
        "\n",
        "- Visualizes both error regions under the null and alternative distributions\n",
        "\n",
        "- Helps you understand how sample size, effect size, and significance level affect the power of the test\n",
        "\n",
        "# Python Function to Calculate & Visualize Type I and Type II Errors:"
      ],
      "metadata": {
        "id": "qZ52BLt19n9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu0, mu1, sigma, n, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II error regions for a two-tailed Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - mu0: Mean under null hypothesis (H0)\n",
        "    - mu1: Mean under alternative hypothesis (H1)\n",
        "    - sigma: Population standard deviation\n",
        "    - n: Sample size\n",
        "    - alpha: Significance level (default 0.05)\n",
        "    \"\"\"\n",
        "\n",
        "    # Standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Z critical values for two-tailed test\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Critical sample means (bounds for rejection region under H0)\n",
        "    x_lower = mu0 - z_critical * se\n",
        "    x_upper = mu0 + z_critical * se\n",
        "\n",
        "    # Define x values for plotting\n",
        "    x = np.linspace(mu0 - 4*se, mu1 + 4*se, 1000)\n",
        "\n",
        "    # PDF for null and alternative distributions\n",
        "    y_null = norm.pdf(x, mu0, se)\n",
        "    y_alt = norm.pdf(x, mu1, se)\n",
        "\n",
        "    # Calculate Type II error (Œ≤): area under H1 curve in acceptance region\n",
        "    beta = norm.cdf(x_upper, mu1, se) - norm.cdf(x_lower, mu1, se)\n",
        "    power = 1 - beta\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y_null, label='H‚ÇÄ: Œº = {}'.format(mu0), color='blue')\n",
        "    plt.plot(x, y_alt, label='H‚ÇÅ: Œº = {}'.format(mu1), color='green')\n",
        "\n",
        "    # Shade Type I error regions (Œ±)\n",
        "    plt.fill_between(x, y_null, where=(x <= x_lower) | (x >= x_upper), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "\n",
        "    # Shade Type II error region (Œ≤)\n",
        "    plt.fill_between(x, y_alt, where=(x > x_lower) & (x < x_upper), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "\n",
        "    # Annotations\n",
        "    plt.axvline(x_lower, color='gray', linestyle='--')\n",
        "    plt.axvline(x_upper, color='gray', linestyle='--')\n",
        "\n",
        "    plt.title('Visualization of Type I and Type II Errors')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print error values\n",
        "    print(f\"Significance level (Œ±): {alpha}\")\n",
        "    print(f\"Type II Error (Œ≤): {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - Œ≤): {power:.4f}\")\n"
      ],
      "metadata": {
        "id": "rpXOWXR692Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Usage:"
      ],
      "metadata": {
        "id": "6XS5rRKn968T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters:\n",
        "mu0 = 100     # Null hypothesis mean\n",
        "mu1 = 105     # Alternative hypothesis mean\n",
        "sigma = 10    # Population standard deviation\n",
        "n = 30        # Sample size\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "visualize_type1_type2_errors(mu0, mu1, sigma, n, alpha)\n"
      ],
      "metadata": {
        "id": "XyPhGR8U984e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results .\n",
        "\n",
        "#Python Code: Independent T-Test"
      ],
      "metadata": {
        "id": "DhWxEcu0-AwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data for two independent groups\n",
        "group1 = [88, 92, 85, 91, 87]\n",
        "group2 = [82, 79, 84, 76, 80]\n",
        "\n",
        "# Perform independent two-sample t-test (assumes equal variance by default)\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "# Output results\n",
        "print(\"Group 1 Mean:\", np.mean(group1))\n",
        "print(\"Group 2 Mean:\", np.mean(group2))\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference between groups).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "tfaNX6apDTvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a paired sample T-test using Python and visualize the comparison results .\n",
        "\n",
        "#Python Code: Paired Sample T-Test with Visualization"
      ],
      "metadata": {
        "id": "ujDhL_D4DXF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Simulated paired data (e.g., scores before and after training)\n",
        "before = [72, 75, 78, 70, 69, 73, 74, 76]\n",
        "after  = [75, 78, 80, 73, 71, 77, 76, 79]\n",
        "\n",
        "# Perform paired t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Display results\n",
        "print(\"Before Mean:\", np.mean(before))\n",
        "print(\"After Mean:\", np.mean(after))\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference between paired samples).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n",
        "# ----- Visualization -----\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "x = np.arange(len(before))\n",
        "plt.plot(x, before, marker='o', label='Before', color='blue')\n",
        "plt.plot(x, after, marker='o', label='After', color='green')\n",
        "for i in range(len(before)):\n",
        "    plt.plot([x[i], x[i]], [before[i], after[i]], color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.title(\"Paired Sample Comparison (Before vs After)\")\n",
        "plt.xlabel(\"Subject\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uNPlEbtBDfzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Simulate data and perform both Z-test and T-test, then compare the results using Python .\n",
        "\n",
        "# Python Code: Simulate Data & Compare Z-test vs T-test"
      ],
      "metadata": {
        "id": "Jfm02LHiDlTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(0)  # For reproducibility\n",
        "sample_size = 25\n",
        "population_mean = 100\n",
        "population_std = 15  # Known population standard deviation (for Z-test)\n",
        "\n",
        "sample = np.random.normal(loc=102, scale=15, size=sample_size)  # Sample mean ~102\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "\n",
        "# Step 2: Perform Z-test (population std known)\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "z_p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: Perform T-test (sample std used)\n",
        "t_stat = (sample_mean - population_mean) / (sample_std / np.sqrt(sample_size))\n",
        "df = sample_size - 1\n",
        "t_p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "# Step 4: Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std:.2f}\\n\")\n",
        "\n",
        "print(\"Z-Test Results:\")\n",
        "print(f\"  Z-score: {z_score:.3f}\")\n",
        "print(f\"  P-value: {z_p_value:.4f}\")\n",
        "\n",
        "print(\"\\nT-Test Results:\")\n",
        "print(f\"  T-statistic: {t_stat:.3f}\")\n",
        "print(f\"  P-value: {t_p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\nInterpretation:\")\n",
        "if z_p_value < alpha:\n",
        "    print(\"  Z-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"  Z-test: Fail to reject the null hypothesis.\")\n",
        "\n",
        "if t_p_value < alpha:\n",
        "    print(\"  T-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"  T-test: Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "OAxlX-tpDvEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "\n",
        "#Python Function: Confidence Interval for Sample Mean"
      ],
      "metadata": {
        "id": "cdR8gY_xDy4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or array of sample observations\n",
        "    - confidence: confidence level (default = 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound)\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    df = n - 1  # degrees of freedom\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df)  # critical t value\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "    lower = mean - margin_of_error\n",
        "    upper = mean + margin_of_error\n",
        "\n",
        "    return lower, upper, mean, margin_of_error\n"
      ],
      "metadata": {
        "id": "3MxV_3AHEBal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Usage:"
      ],
      "metadata": {
        "id": "fm5_eSIrECWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "sample_data = [88, 90, 92, 85, 87, 91, 89]\n",
        "\n",
        "# Calculate 95% confidence interval\n",
        "lower, upper, mean, moe = confidence_interval(sample_data, confidence=0.95)\n",
        "\n",
        "print(f\"Sample Mean: {mean:.2f}\")\n",
        "print(f\"Margin of Error: {moe:.2f}\")\n",
        "print(f\"95% Confidence Interval: ({lower:.2f}, {upper:.2f})\")\n"
      ],
      "metadata": {
        "id": "OTkiFhveEEg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data .\n",
        "# Python Code: Calculate Margin of Error"
      ],
      "metadata": {
        "id": "KcBK6sQlEIHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def calculate_margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the margin of error for a sample mean using the T-distribution.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or array of sample values\n",
        "    - confidence: confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - margin of error\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    sample_std = np.std(data, ddof=1)\n",
        "    std_err = sample_std / np.sqrt(n)\n",
        "    df = n - 1\n",
        "\n",
        "    # Critical t-value\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "sample_data = [72, 75, 78, 70, 69, 73, 74, 76]\n",
        "\n",
        "confidence_level = 0.95\n",
        "moe = calculate_margin_of_error(sample_data, confidence=confidence_level)\n",
        "\n",
        "print(f\"Sample Size: {len(sample_data)}\")\n",
        "print(f\"Confidence Level: {int(confidence_level * 100)}%\")\n",
        "print(f\"Margin of Error: ¬±{moe:.2f}\")\n"
      ],
      "metadata": {
        "id": "TkjXM-LxERiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process .\n",
        "\n",
        "# Python Code: Bayesian Inference Example\n",
        "- We'll simulate a medical test scenario where:\n",
        "   - Disease affects 1% of the population\n",
        "\n",
        "   - Test is 95% accurate for positives and 90% accurate for negatives"
      ],
      "metadata": {
        "id": "Sr--cC8MEXJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_inference(prior, sensitivity, specificity):\n",
        "    \"\"\"\n",
        "    Computes the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - prior: P(Disease) ‚Üí prior probability of the hypothesis\n",
        "    - sensitivity: P(Test+ | Disease) ‚Üí true positive rate\n",
        "    - specificity: P(Test- | No Disease) ‚Üí true negative rate\n",
        "\n",
        "    Returns:\n",
        "    - posterior: P(Disease | Test+)\n",
        "    \"\"\"\n",
        "\n",
        "    # Complement probabilities\n",
        "    p_disease = prior\n",
        "    p_no_disease = 1 - prior\n",
        "    p_test_given_disease = sensitivity\n",
        "    p_test_given_no_disease = 1 - specificity\n",
        "\n",
        "    # Bayes' Theorem\n",
        "    numerator = p_test_given_disease * p_disease\n",
        "    denominator = (p_test_given_disease * p_disease) + (p_test_given_no_disease * p_no_disease)\n",
        "\n",
        "    posterior = numerator / denominator\n",
        "    return posterior\n",
        "\n",
        "# Example: Disease test\n",
        "prior = 0.01          # 1% of people have the disease\n",
        "sensitivity = 0.95    # Test correctly identifies 95% of cases\n",
        "specificity = 0.90    # Test correctly identifies 90% of non-cases\n",
        "\n",
        "posterior = bayesian_inference(prior, sensitivity, specificity)\n",
        "print(f\"Probability of having the disease given a positive test result: {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "WLJOcGPGE11F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output Example:"
      ],
      "metadata": {
        "id": "Iqkvox8gE6wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Probability of having the disease given a positive test result: 0.0876\n"
      ],
      "metadata": {
        "id": "5NcTi9-TE8Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only ~8.76% chance the person actually has the disease, even after a positive test"
      ],
      "metadata": {
        "id": "h5friL01E9_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform a Chi-square test for independence between two categorical variables in Python .\n",
        "\n",
        "#Steps for Chi-Square Test for Independence:\n",
        "- Create a contingency table.\n",
        "- Use scipy.stats.chi2_contingency() to calculate:\n",
        "   - Chi-square statistic\n",
        "\n",
        "   - p-value\n",
        "\n",
        "   - degrees of freedom\n",
        "\n",
        "   - expected frequencies\n",
        "\n",
        "- Interpret the result.\n",
        "\n",
        "\n",
        "#Python Code Example: Chi-Square Test for Independence\n"
      ],
      "metadata": {
        "id": "lhGTC0ftFDoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Create a contingency table (e.g., Gender vs Preference)\n",
        "# Rows = Gender (Male, Female), Columns = Preference (A, B)\n",
        "data = [[30, 10],   # Male\n",
        "        [20, 40]]   # Female\n",
        "\n",
        "table = pd.DataFrame(data, columns=['Preference_A', 'Preference_B'], index=['Male', 'Female'])\n",
        "\n",
        "# Step 2: Perform the Chi-square test\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(table)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(\"Contingency Table:\")\n",
        "print(table)\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(pd.DataFrame(expected, columns=table.columns, index=table.index))\n",
        "\n",
        "print(f\"\\nChi-square Statistic: {chi2_stat:.3f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. Variables are dependent (associated).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant association.\")\n"
      ],
      "metadata": {
        "id": "0hrxhUy4FiOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Output:"
      ],
      "metadata": {
        "id": "QHfom_U3FmbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Chi-square Statistic: 16.071\n",
        "Degrees of Freedom: 1\n",
        "P-value: 0.0001\n",
        "Conclusion: Reject the null hypothesis. Variables are dependent (associated).\n"
      ],
      "metadata": {
        "id": "yl2ZLdYpFoGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data.\n",
        "\n",
        "#Python Code: Calculate Expected Frequencies"
      ],
      "metadata": {
        "id": "BEnk9676FrQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Create observed data (contingency table)\n",
        "# Example: Gender (Male, Female) vs Preference (A, B)\n",
        "observed = np.array([[30, 10],   # Male\n",
        "                     [20, 40]])  # Female\n",
        "\n",
        "# Convert to DataFrame for better display\n",
        "table = pd.DataFrame(observed, columns=[\"Preference_A\", \"Preference_B\"], index=[\"Male\", \"Female\"])\n",
        "\n",
        "# Step 2: Use chi2_contingency to get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
        "\n",
        "# Step 3: Display results\n",
        "print(\"Observed Frequencies:\")\n",
        "print(table)\n",
        "\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "expected_df = pd.DataFrame(expected, columns=table.columns, index=table.index)\n",
        "print(expected_df.round(2))\n",
        "\n"
      ],
      "metadata": {
        "id": "Tls4W0SjF1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How Expected Frequencies Are Calculated:\n",
        "Each expected frequency is calculated as:\n",
        "\n",
        "ùê∏\n",
        "ùëñ\n",
        "ùëó\n",
        "=\n",
        "(\n",
        "ùëÖ\n",
        "ùëú\n",
        "ùë§\n",
        "\n",
        "ùëá\n",
        "ùëú\n",
        "ùë°\n",
        "ùëé\n",
        "ùëô\n",
        "ùëñ\n",
        "√ó\n",
        "ùê∂\n",
        "ùëú\n",
        "ùëô\n",
        "ùë¢\n",
        "ùëö\n",
        "ùëõ\n",
        "\n",
        "ùëá\n",
        "ùëú\n",
        "ùë°\n",
        "ùëé\n",
        "ùëô\n",
        "ùëó\n",
        ")\n",
        "ùê∫\n",
        "ùëü\n",
        "ùëé\n",
        "ùëõ\n",
        "ùëë\n",
        "\n",
        "ùëá\n",
        "ùëú\n",
        "ùë°\n",
        "ùëé\n",
        "ùëô\n",
        "E\n",
        "ij\n",
        "‚Äã\n",
        " =\n",
        "Grand¬†Total\n",
        "(Row¬†Total\n",
        "i\n",
        "‚Äã\n",
        " √óColumn¬†Total\n",
        "j\n",
        "‚Äã\n",
        " )\n",
        "‚Äã\n"
      ],
      "metadata": {
        "id": "AfHOhoH2GFVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Output:"
      ],
      "metadata": {
        "id": "RZbZO-JdGNz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Observed Frequencies:\n",
        "        Preference_A  Preference_B\n",
        "Male              30            10\n",
        "Female            20            40\n",
        "\n",
        "Expected Frequencies:\n",
        "        Preference_A  Preference_B\n",
        "Male            20.0          20.0\n",
        "Female          30.0          30.0\n"
      ],
      "metadata": {
        "id": "9Qur_FmjGOzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution .\n",
        "\n",
        "#Steps for Goodness-of-Fit Test:\n",
        "- 1. Define observed frequencies (from your data).\n",
        "\n",
        "- 2. Define expected frequencies (based on a theoretical distribution or assumption).\n",
        "\n",
        "- 3. Use scipy.stats.chisquare() to perform the test.\n",
        "\n",
        "- 4. Interpret the result.\n",
        "\n",
        "# Python Code: Chi-square Goodness-of-Fit Test"
      ],
      "metadata": {
        "id": "zjLCEJt8GUCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Step 1: Observed data (e.g., categories: A, B, C)\n",
        "observed = np.array([25, 30, 45])\n",
        "\n",
        "# Step 2: Expected distribution (e.g., uniform or specific ratio)\n",
        "# Example: Expected proportions are equal (uniform distribution)\n",
        "expected = np.array([33.33, 33.33, 33.33])  # Or use expected = np.full(3, np.sum(observed) / 3)\n",
        "\n",
        "# Step 3: Perform the Chi-square goodness-of-fit test\n",
        "chi_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(\"Observed Frequencies:\", observed)\n",
        "print(\"Expected Frequencies:\", expected.round(2))\n",
        "print(f\"\\nChi-square Statistic: {chi_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The data does not fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. The data fits the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "gPnpAJwDGnVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics .\n",
        "\n",
        "#Python Script: Simulate and Visualize Chi-Square Distribution"
      ],
      "metadata": {
        "id": "IC6zFrhFGtJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Set up degrees of freedom to visualize\n",
        "dfs = [1, 2, 5, 10, 20]\n",
        "\n",
        "# Create a range of x values\n",
        "x = np.linspace(0, 40, 500)\n",
        "\n",
        "# Plot the Chi-square distribution for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "for df in dfs:\n",
        "    y = chi2.pdf(x, df)\n",
        "    plt.plot(x, y, label=f'df = {df}')\n",
        "\n",
        "# Plot settings\n",
        "plt.title('Chi-Square Distribution for Various Degrees of Freedom')\n",
        "plt.xlabel('Chi-square value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f8KGPAYKG1bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  Implement an F-test using Python to compare the variances of two random samples .\n",
        "\n",
        "# Python Code: F-Test for Equality of Variances"
      ],
      "metadata": {
        "id": "Q8l10cuxG5CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "def f_test(sample1, sample2):\n",
        "    # Sample sizes\n",
        "    n1 = len(sample1)\n",
        "    n2 = len(sample2)\n",
        "\n",
        "    # Sample variances\n",
        "    var1 = np.var(sample1, ddof=1)\n",
        "    var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "    # Ensure F is the ratio of the larger to smaller variance\n",
        "    if var1 > var2:\n",
        "        F = var1 / var2\n",
        "        df1, df2 = n1 - 1, n2 - 1\n",
        "    else:\n",
        "        F = var2 / var1\n",
        "        df1, df2 = n2 - 1, n1 - 1\n",
        "\n",
        "    # p-value (two-tailed)\n",
        "    p_value = 2 * min(f.cdf(F, df1, df2), 1 - f.cdf(F, df1, df2))\n",
        "\n",
        "    return F, p_value, df1, df2\n",
        "\n",
        "# üî¢ Example: Simulate two random samples\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "sample2 = np.random.normal(loc=50, scale=20, size=30)\n",
        "\n",
        "# Perform F-test\n",
        "F_stat, p_val, df1, df2 = f_test(sample1, sample2)\n",
        "\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: {df1}, {df2}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "\n",
        "# Interpret\n",
        "alpha = 0.\n"
      ],
      "metadata": {
        "id": "_FT_QeMCHJVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "interpret the results.\n",
        "\n",
        "#Python Code: One-Way ANOVA"
      ],
      "metadata": {
        "id": "yu9SaJrBHNXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate data for multiple groups\n",
        "np.random.seed(42)\n",
        "\n",
        "group1 = np.random.normal(loc=50, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=52, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=55, scale=5, size=30)\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference between group means.\")\n"
      ],
      "metadata": {
        "id": "nGhiYBicHYeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Output:"
      ],
      "metadata": {
        "id": "-Id8GwkBHfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANOVA Results:\n",
        "F-statistic: 8.1452\n",
        "P-value: 0.0006\n",
        "Conclusion: Reject the null hypothesis. At least one group mean is significantly different.\n"
      ],
      "metadata": {
        "id": "QHQ2RtW2HgWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results .\n",
        "\n",
        "#One-Way ANOVA with Plot (Boxplot)"
      ],
      "metadata": {
        "id": "K57Tk_SEHlq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate sample data for 3 groups\n",
        "np.random.seed(1)\n",
        "group_A = np.random.normal(loc=60, scale=5, size=30)\n",
        "group_B = np.random.normal(loc=65, scale=5, size=30)\n",
        "group_C = np.random.normal(loc=70, scale=5, size=30)\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group_A, group_B, group_C)\n",
        "\n",
        "# Step 3: Print ANOVA results\n",
        "print(\"ANOVA Test Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis ‚Äî at least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis ‚Äî no significant difference in means.\")\n",
        "\n",
        "# Step 4: Prepare data for plotting\n",
        "df = pd.DataFrame({\n",
        "    'Scores': np.concatenate([group_A, group_B, group_C]),\n",
        "    'Group': ['A'] * len(group_A) + ['B'] * len(group_B) + ['C'] * len(group_C)\n",
        "})\n",
        "\n",
        "# Step 5: Plot the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns\n"
      ],
      "metadata": {
        "id": "CNFyaYZSHsZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA .\n",
        "\n",
        "#Python Function: Check ANOVA Assumptions"
      ],
      "metadata": {
        "id": "H6gJY9k-H0_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(data, group_col, value_col, plot=True):\n",
        "    grouped = data.groupby(group_col)[value_col]\n",
        "    results = {}\n",
        "\n",
        "    print(\"---- Normality (Shapiro-Wilk Test) ----\")\n",
        "    for name, group in grouped:\n",
        "        stat, p = shapiro(group)\n",
        "        results[name] = {'Shapiro-Wilk p-value': p}\n",
        "        print(f\"Group {name}: p = {p:.4f} {'‚úÖ' if p > 0.05 else '‚ùå'}\")\n",
        "\n",
        "    print(\"\\n---- Homogeneity of Variances (Levene‚Äôs Test) ----\")\n",
        "    groups = [group for name, group in grouped]\n",
        "    stat, p = levene(*groups)\n",
        "    results['Levene‚Äôs Test'] = {'p-value': p}\n",
        "    print(f\"Levene‚Äôs Test: p = {p:.4f} {'‚úÖ' if p > 0.05 else '‚ùå'}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Independence assumption should be based on study design (not tested here).\")\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 5))\n"
      ],
      "metadata": {
        "id": "OxRHAGc7H9Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How to Use It:"
      ],
      "metadata": {
        "id": "w_PGLTY4IAg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate example data\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame({\n",
        "    'Group': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
        "    'Score': np.concatenate([\n",
        "        np.random.normal(60, 5, 30),\n",
        "        np.random.normal(62, 5, 30),\n",
        "        np.random.normal(65, 5, 30)\n",
        "    ])\n",
        "})\n",
        "\n",
        "# Run assumption checks\n",
        "check_anova_assumptions(df, group_col='Group', value_col='Score')\n"
      ],
      "metadata": {
        "id": "NXoIL8Y0IDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the\n",
        "results .\n",
        "\n",
        "#Two-Way ANOVA with Interaction in Python"
      ],
      "metadata": {
        "id": "h5G8WfswIH1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(1)\n",
        "df = pd.DataFrame({\n",
        "    'FactorA': np.repeat(['Low', 'High'], 30),\n",
        "    'FactorB': np.tile(np.repeat(['X', 'Y', 'Z'], 10), 2),\n",
        "    'Score': np.random.normal(loc=50, scale=5, size=60)\n",
        "})\n",
        "# Introduce interaction effect\n",
        "df.loc[(df['FactorA'] == 'High') & (df['FactorB'] == 'Z'), 'Score'] += 10\n",
        "\n",
        "# Two-way ANOVA with interaction\n",
        "model = ols('Score ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.pointplot(x='FactorB', y='Score', hue='FactorA', data=df, capsize=.1, palette='pastel', dodge=True)\n",
        "plt.title('Interaction Plot: FactorA vs FactorB')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wK0yDeYeIURT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing.\n",
        "\n",
        "#Python Program: Visualize F-Distribution"
      ],
      "metadata": {
        "id": "wDBRt85oIX5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Define degrees of freedom\n",
        "df1, df2 = 5, 20\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "# Plot F-distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})', color='skyblue')\n",
        "plt.fill_between(x, y, where=(x > f.ppf(0.95, df1, df2)), color='red', alpha=0.3, label='Critical region (_\n"
      ],
      "metadata": {
        "id": "2xY2mu1NIoVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.  Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means .\n",
        "\n",
        "#One-Way ANOVA with Boxplot in Python\n",
        "\n"
      ],
      "metadata": {
        "id": "diCL53ELIuba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate data for 3 groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=60, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=65, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=70, scale=5, size=30)\n",
        "\n",
        "# Step 2: Combine data into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Score': np.concatenate([group1, group2, group3]),\n",
        "    'Group': ['Group 1'] * 30 + ['Group 2'] * 30 + ['Group 3'] * 30\n",
        "})\n",
        "\n",
        "# Step 3: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"One-Way ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4_\n"
      ],
      "metadata": {
        "id": "HqRRH9j8I3Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.  Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means .\n",
        "\n",
        "# Python: Simulate & Test Mean"
      ],
      "metadata": {
        "id": "Y0xl-hECI9T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Simulate data from N(Œº=50, œÉ=5)\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=5, size=30)\n",
        "\n",
        "# Perform one-sample t-test against population mean = 52\n",
        "t_stat, p_value = ttest_1samp(data, popmean=52)\n",
        "\n",
        "print(\"One-Sample T-Test Results:\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The sample mean is significantly different from 52.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference from 52.\")\n"
      ],
      "metadata": {
        "id": "TCOyPK5vI-o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results .\n",
        "\n",
        "#Python Code: Variance Test using Chi-Square"
      ],
      "metadata": {
        "id": "erU-GxqwJKCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Simulate sample data\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=50, scale=5, size=30)  # œÉ = 5 ‚áí variance = 25\n",
        "\n",
        "# Hypothesized population variance (œÉ‚ÇÄ¬≤)\n",
        "sigma_sq_0 = 20\n",
        "\n",
        "# Calculate sample variance\n",
        "n = len(sample)\n",
        "sample_var = np.var(sample, ddof=1)  # sample variance with Bessel's correction\n",
        "\n",
        "# Chi-square test statistic\n",
        "chi2_stat = (n - 1) * sample_var / sigma_sq_0\n",
        "\n",
        "# Degrees of freedom\n",
        "df = n - 1\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Critical\n"
      ],
      "metadata": {
        "id": "fLGQoFEQJTGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.  Write a Python script to perform a Z-test for comparing proportions between two datasets or groups .\n",
        "\n",
        "#Z-Test for Two Proportions ‚Äì Python Script"
      ],
      "metadata": {
        "id": "dwmDPLD9Jbh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Example data: Group A and Group B\n",
        "successes = [45, 30]       # Number of successes in each group\n",
        "n_obs = [100, 100]         # Total observations in each group\n",
        "\n",
        "# Perform Z-test for proportions\n",
        "z_stat, p_value = proportions_ztest(successes, n_obs)\n",
        "\n",
        "print(\"Z-Test for Two Proportions:\")\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference in proportions.\")\n"
      ],
      "metadata": {
        "id": "SOuW3OIwJi9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.  Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results .\n",
        "\n",
        "#Python Code: F-Test for Variance Comparison\n"
      ],
      "metadata": {
        "id": "L5SNVnfjJl8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Step 1: Simulate two datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=10, size=30)  # variance ~ 100\n",
        "data2 = np.random.normal(loc=55, scale=7, size=30)   # variance ~ 49\n",
        "\n",
        "# Step 2: Calculate sample variances\n",
        "var1 = np.var(data1, ddof=1)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "\n",
        "# Step 3: Perform F-test\n",
        "f_stat = var1 / var2\n",
        "df1 = len(data1) - 1\n",
        "df2 = len(data2) - 1\n",
        "alpha = 0.05\n",
        "\n",
        "# Critical values for two-tailed test\n",
        "f_critical_low = f.ppf(alpha / 2, df1, df2)\n",
        "f_critical_high = f.ppf(1 - alpha / 2, df1, df2)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"F-Test to Compare Variances:\")\n",
        "print(f\"Sample variance 1: {var1:.2f}\")\n",
        "print(f\"Sample variance 2: {var2:.2f}\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"Critical range: ({f_critical_low:.4f}, {f_critical_high:.4f})\")\n",
        "\n",
        "# Step 5: Interpret result\n",
        "if f_stat < f_critical_low or f_stat > f_critical_high:\n",
        "    print(\"Conclusion: Reject null hypothesis ‚Äì variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject null hypothesis ‚Äì no significant difference in variances.\")\n",
        "\n",
        "# Step 6: Visualize F-distribution and test result\n",
        "x = np.linspace(0.1, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label='F-distribution', color='skyblue')\n",
        "plt.axvline(f_stat, color='green', linestyle='--', label=f'F-stat = {f_stat:.2f}')\n",
        "plt.axvline(f_critical_low, color='red', linestyle='--', label='Critical values')\n",
        "plt.axvline(f_critical_high, color='red', linestyle='--')\n",
        "\n",
        "plt.fill_between(x, y, where=(x < f_critical_low) | (x > f_critical_high), color='red', alpha=0.2)\n",
        "plt.title('F-Distribution and Critical Regions')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--',\n"
      ],
      "metadata": {
        "id": "WI80GwiEJw4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "\n",
        "#Python Code: Chi-square Goodness-of-Fit Test"
      ],
      "metadata": {
        "id": "_X_fYuoNJ2tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate observed data (e.g., frequencies of 4 categories)\n",
        "np.random.seed(42)\n",
        "observed = np.random.multinomial(100, [0.3, 0.2, 0.3, 0.2])  # Not perfectly uniform\n",
        "\n",
        "# Step 2: Define expected frequencies (e.g., uniform distribution)\n",
        "expected = [25, 25, 25, 25]  # Expecting equal frequency in 4 categories\n",
        "\n",
        "# Step 3: Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"Chi-square Goodness-of-Fit Test:\")\n",
        "print(f\"Observed: {observed}\")\n",
        "print(f\"Expected: {expected}\")\n",
        "print(f\"Chi2 Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. Observed data does not fit expected distribution.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. Observed data fits the expected distribution.\")\n",
        "\n",
        "# Step 6: Visualization\n",
        "categories = ['A', 'B', 'C', 'D']\n",
        "x = np.arange(len(categories))\n",
        "plt.bar(x - 0.2, observed, width=0.4, label='Observed', color='skyblue')\n",
        "plt.bar(x + 0.2, expected, width=0.4, label='Expected', color='orange')\n",
        "plt.xticks(x, categories)\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Observed vs Expected Frequencies')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yucd1jDRJ_4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}