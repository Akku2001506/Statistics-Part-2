{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Part 2"
      ],
      "metadata": {
        "id": "Q7JQIg1k0mno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics ?\n",
        "\n",
        "- Hypothesis testing in statistics is a method used to decide whether there is enough evidence to support a specific claim (hypothesis) about a population, based on sample data. It involves:\n",
        "\n",
        "1. **Null hypothesis (H₀):** The default assumption (e.g., no effect or no difference).\n",
        "2. **Alternative hypothesis (H₁):** What you want to test (e.g., there is an effect).\n",
        "3. **P-value:** Probability of observing the data if H₀ is true.\n",
        "4. **Decision:** If the p-value is less than the significance level (e.g., 0.05), reject H₀.\n",
        "\n",
        "In short, it's a way to test assumptions using data.\n",
        "\n",
        "----\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis ?\n",
        "\n",
        "- The **null hypothesis (H₀)** is the assumption that there is no effect or no difference. The **alternative hypothesis (H₁ or Ha)** is the claim that there **is** an effect or a difference.\n",
        "\n",
        "**Difference:**  \n",
        "- H₀: Status quo or default (e.g., mean = 50)  \n",
        "- H₁: What you're trying to prove (e.g., mean ≠ 50)\n",
        "\n",
        "We test data to decide whether to reject H₀ in favor of H₁.\n",
        "\n",
        "----\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important ?\n",
        "\n",
        "- The **significance level** (denoted as **α**) is the probability of rejecting the null hypothesis when it is actually true — also called the **risk of a false positive**.\n",
        "\n",
        "Common values: **0.05**, **0.01**, or **0.10**.\n",
        "\n",
        "**Why it's important:**  \n",
        "It sets the **threshold** for how much evidence is needed to reject the null hypothesis. A lower α means stricter evidence is required, reducing the chance of a false claim.\n",
        "\n",
        "-----\n",
        "4. What does a P-value represent in hypothesis testing ?\n",
        "- A **p-value** is the probability of getting results as extreme as (or more extreme than) the observed data, **assuming the null hypothesis is true**.\n",
        "\n",
        "**In simple terms:**  \n",
        "It tells us how likely our results are due to chance.\n",
        "\n",
        "- **Low p-value (≤ α):** Strong evidence against H₀ → reject H₀  \n",
        "- **High p-value (> α):** Weak evidence against H₀ → fail to reject H₀\n",
        "\n",
        "It helps decide whether the results are statistically significant.\n",
        "\n",
        "----\n",
        "5. How do you interpret the P-value in hypothesis testing ?\n",
        "\n",
        "- **Interpreting the p-value:**\n",
        "\n",
        "- **If p-value ≤ significance level (α):**  \n",
        "  → Reject the null hypothesis (H₀).  \n",
        "  → The result is **statistically significant** (unlikely due to chance).\n",
        "\n",
        "- **If p-value > significance level (α):**  \n",
        "  → Fail to reject the null hypothesis.  \n",
        "  → The result is **not statistically significant** (could be due to chance).\n",
        "\n",
        "**Example:**  \n",
        "If α = 0.05 and p = 0.03 → reject H₀ (significant result).  \n",
        "If p = 0.08 → do not reject H₀ (not significant).\n",
        "\n",
        "----\n",
        "6.  What are Type 1 and Type 2 errors in hypothesis testing ?\n",
        "- In hypothesis testing:\n",
        "\n",
        "- **Type I Error (False Positive):**  \n",
        "  Rejecting the **null hypothesis (H₀)** when it is actually **true**.  \n",
        "  - Probability = **α** (significance level)\n",
        "\n",
        "- **Type II Error (False Negative):**  \n",
        "  Failing to reject the **null hypothesis** when the **alternative hypothesis (H₁)** is actually **true**.  \n",
        "  - Probability = **β**\n",
        "\n",
        "**Simple example:**  \n",
        "- Type I: Saying a drug works when it actually doesn't.  \n",
        "- Type II: Saying a drug doesn't work when it actually does.\n",
        "\n",
        "----\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing ?\n",
        "\n",
        "- **One-tailed test:**  \n",
        "- Tests for an effect in **one specific direction** (e.g., greater than or less than).  \n",
        "- Example: H₁: mean > 50\n",
        "\n",
        "**Two-tailed test:**  \n",
        "- Tests for an effect in **either direction** (e.g., not equal).  \n",
        "- Example: H₁: mean ≠ 50\n",
        "\n",
        "**Key difference:**  \n",
        "- **One-tailed** looks for an effect on **one side** of the distribution.  \n",
        "- **Two-tailed** looks for an effect on **both sides**.\n",
        "\n",
        "----\n",
        "8. What is the Z-test, and when is it used in hypothesis testing ?\n",
        "- The **Z-test** is a statistical test used to determine whether there is a significant difference between sample and population means (or between two sample means), **when the population standard deviation is known** and the sample size is large (n ≥ 30).\n",
        "\n",
        "**When to use it:**\n",
        "- Population standard deviation (σ) is known  \n",
        "- Sample size is large  \n",
        "- Data is approximately normally distributed\n",
        "\n",
        "**Examples:**\n",
        "- Testing if a sample mean differs from a known population mean  \n",
        "- Comparing two means when variances are known and large samples are used\n",
        "\n",
        "-----\n",
        "9.  How do you calculate the Z-score, and what does it represent in hypothesis testing ?\n",
        "- **Z-score formula (for a sample mean):**  \n",
        "\\[\n",
        "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( \\bar{X} \\) = sample mean  \n",
        "- \\( \\mu \\) = population mean  \n",
        "- \\( \\sigma \\) = population standard deviation  \n",
        "- \\( n \\) = sample size\n",
        "\n",
        "**What it represents:**  \n",
        "The **Z-score** tells you how many **standard deviations** the sample mean is from the population mean.  \n",
        "\n",
        "In hypothesis testing, it helps determine how unusual the sample result is under the null hypothesis — and is used to find the **p-value**.\n",
        "----\n",
        "\n",
        "10.  What is the T-distribution, and when should it be used instead of the normal distribution ?\n",
        "- The **T-distribution** is a probability distribution used in statistics when estimating population parameters **with small sample sizes** and/or when the **population standard deviation is unknown**.\n",
        "\n",
        "### Use the **T-distribution** when:\n",
        "- Sample size is **small** (typically **n < 30**)  \n",
        "- **Population standard deviation (σ)** is **unknown**  \n",
        "- Data is approximately **normally distributed**\n",
        "\n",
        "### Why it's used:\n",
        "The T-distribution is **wider and has heavier tails** than the normal distribution, which accounts for extra uncertainty in small samples.\n",
        "\n",
        "As sample size increases, the T-distribution becomes more like the **normal distribution**.\n",
        "\n",
        "------\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test ?\n",
        "\n",
        "- **Z-test vs. T-test:**\n",
        "\n",
        "| Feature              | **Z-test**                                     | **T-test**                                      |\n",
        "|----------------------|------------------------------------------------|-------------------------------------------------|\n",
        "| **Population SD known?** | Yes                                            | No                                              |\n",
        "| **Sample size**      | Large (n ≥ 30)                                | Small (n < 30)                                  |\n",
        "| **Distribution used**| Normal distribution                           | T-distribution                                  |\n",
        "| **Use case**         | Comparing means when population SD is known   | Comparing means when population SD is unknown   |\n",
        "\n",
        "**In short:**  \n",
        "- Use **Z-test** when the sample is large **and** σ is known.  \n",
        "- Use **T-test** when the sample is small **or** σ is unknown.\n",
        "\n",
        "-----\n",
        "12. What is the T-test, and how is it used in hypothesis testing ?\n",
        "- The **T-test** is a statistical test used to compare means and determine if the difference between them is **statistically significant**, especially when the **population standard deviation is unknown**.\n",
        "\n",
        "### **Types of T-tests:**\n",
        "1. **One-sample T-test:**  \n",
        "   Tests if the sample mean differs from a known value.\n",
        "2. **Two-sample (independent) T-test:**  \n",
        "   Compares means from two independent groups.\n",
        "3. **Paired T-test:**  \n",
        "   Compares means from the same group at different times.\n",
        "\n",
        "### **How it's used:**\n",
        "- Set up null (H₀) and alternative (H₁) hypotheses  \n",
        "- Calculate the **t-statistic**  \n",
        "- Compare with critical value or use the **p-value**  \n",
        "- Make a decision: reject or fail to reject H₀\n",
        "\n",
        "It’s especially useful for small sample sizes and unknown population standard deviations.\n",
        "----\n",
        "\n",
        "13.  What is the relationship between Z-test and T-test in hypothesis testing ?\n",
        "\n",
        "- The **Z-test and T-test** are both used in hypothesis testing to compare means, but they differ mainly in terms of **sample size** and **known vs. unknown population standard deviation**.\n",
        "\n",
        "### **Relationship:**\n",
        "\n",
        "- Both tests check if a sample mean significantly differs from a population mean or another sample mean.\n",
        "- Both follow a similar structure (test statistic, p-value, decision).\n",
        "- The **T-test becomes similar to the Z-test** as the **sample size increases** — because the **T-distribution approaches the normal distribution**.\n",
        "\n",
        "### **Key Difference:**\n",
        "\n",
        "| Condition                 | Use Z-test       | Use T-test       |\n",
        "|--------------------------|------------------|------------------|\n",
        "| Population SD known      | ✅ Yes            | ❌ No             |\n",
        "| Sample size large (n ≥ 30)| ✅ Preferred      | ✅ Can be used    |\n",
        "| Sample size small (n < 30)| ❌ Not ideal      | ✅ Required       |\n",
        "\n",
        "**In short:**  \n",
        "The T-test is a generalization of the Z-test used when there's more uncertainty (like small samples or unknown SD).\n",
        "\n",
        "----\n",
        "\n",
        "14.  What is a confidence interval, and how is it used to interpret statistical results ?\n",
        "- A **confidence interval (CI)** is a range of values that is likely to contain the true population parameter (like a mean or proportion) with a certain level of confidence.\n",
        "\n",
        "### Example:\n",
        "A 95% confidence interval means **we are 95% confident** that the true value lies within that range.\n",
        "\n",
        "### How it's used:\n",
        "- **Estimates uncertainty** in sample results  \n",
        "- **Narrow CI** = more precise estimate  \n",
        "- If the **CI does not include the null hypothesis value** (e.g., mean = 0), the result is **statistically significant**\n",
        "\n",
        "### In short:\n",
        "A confidence interval helps interpret results by showing a likely range for the true value and whether the result is significant.\n",
        "\n",
        "-----\n",
        "15. What is the margin of error, and how does it affect the confidence interval ?\n",
        "- The **margin of error (MoE)** is the amount added and subtracted from the sample estimate to create a **confidence interval**. It reflects the **uncertainty** in the estimate due to sampling.\n",
        "\n",
        "### Formula (basic):\n",
        "\\[\n",
        "\\text{Margin of Error} = z^* \\times \\frac{\\sigma}{\\sqrt{n}}\n",
        "\\]\n",
        "Where:\n",
        "- \\( z^* \\) = critical value (based on confidence level)\n",
        "- \\( \\sigma \\) = standard deviation\n",
        "- \\( n \\) = sample size\n",
        "\n",
        "### **How it affects the confidence interval:**\n",
        "\\[\n",
        "\\text{Confidence Interval} = \\text{Sample Estimate} \\pm \\text{Margin of Error}\n",
        "\\]\n",
        "\n",
        "### Key points:\n",
        "- **Larger MoE → wider confidence interval** → less precision  \n",
        "- **Smaller MoE → narrower interval** → more precision  \n",
        "- MoE decreases with **larger sample sizes** or **lower confidence levels**\n",
        "\n",
        "**In short:**  \n",
        "Margin of error controls the **width** of the confidence interval and reflects the level of uncertainty in the estimate.\n",
        "-----\n",
        "\n",
        "16.  How is Bayes' Theorem used in statistics, and what is its significance ?\n",
        "\n",
        "- **Bayes' Theorem** is used in statistics to **update the probability** of a hypothesis based on **new evidence or data**.\n",
        "\n",
        "### **Formula:**\n",
        "\\[\n",
        "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( P(A|B) \\): Posterior probability (probability of A given B)  \n",
        "- \\( P(B|A) \\): Likelihood (probability of B given A)  \n",
        "- \\( P(A) \\): Prior probability (initial belief about A)  \n",
        "- \\( P(B) \\): Total probability of B\n",
        "\n",
        "### **How it's used:**\n",
        "- In **medical testing** (e.g., chance of disease given a positive test)  \n",
        "- In **machine learning** (e.g., spam filters, classification)  \n",
        "- In **decision making under uncertainty**\n",
        "\n",
        "### **Significance:**\n",
        "Bayes' Theorem allows combining **prior knowledge** with **new data**, making it a powerful tool for **probabilistic reasoning** and **updating beliefs**.\n",
        "\n",
        "-----\n",
        "\n",
        "17.  What is the Chi-square distribution, and when is it used ?\n",
        "- The **Chi-square (χ²) distribution** is a statistical distribution used to test relationships between categorical variables and to assess the **goodness of fit** or **independence** in a dataset.\n",
        "\n",
        "### **When it's used:**\n",
        "\n",
        "1. **Chi-square test of independence:**  \n",
        "   - To check if two categorical variables are related.  \n",
        "   - Example: Is gender related to voting preference?\n",
        "\n",
        "2. **Chi-square goodness-of-fit test:**  \n",
        "   - To see if sample data fits an expected distribution.  \n",
        "   - Example: Do dice rolls follow a uniform distribution?\n",
        "\n",
        "### **Key features:**\n",
        "- Only takes **non-negative** values (starts at 0)  \n",
        "- **Asymmetrical** and **right-skewed**  \n",
        "- Shape depends on **degrees of freedom (df)**\n",
        "\n",
        "### **In short:**  \n",
        "The Chi-square distribution is used to test hypotheses about **categorical data** — mainly to check for **association** or how well observed data fits expected values.\n",
        "\n",
        "----\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied ?\n",
        "- The **Chi-square goodness of fit test** is used to determine whether a set of **observed frequencies** matches **expected frequencies** for a categorical variable.\n",
        "\n",
        "### **Purpose:**  \n",
        "To test if the data follows a specific distribution.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps to apply it:**\n",
        "\n",
        "1. **State hypotheses:**  \n",
        "   - **H₀ (null):** Observed data fits the expected distribution  \n",
        "   - **H₁ (alternative):** Observed data does **not** fit the expected distribution\n",
        "\n",
        "2. **Calculate expected frequencies** based on the assumed distribution.\n",
        "\n",
        "3. **Compute test statistic:**  \n",
        "   \\[\n",
        "   \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
        "   \\]  \n",
        "   Where:\n",
        "   - \\( O_i \\) = observed frequency  \n",
        "   - \\( E_i \\) = expected frequency\n",
        "\n",
        "4. **Compare** the result to a critical value from the **Chi-square distribution table** (based on degrees of freedom and significance level), or find the **p-value**.\n",
        "\n",
        "5. **Decision:**  \n",
        "   - If \\( \\chi^2 \\) is large or p-value < α → reject H₀  \n",
        "   - Otherwise → fail to reject H₀\n",
        "\n",
        "---\n",
        "\n",
        "### **Example use:**  \n",
        "You roll a die 60 times. If each face should appear 10 times (uniform distribution), the test checks whether your actual results significantly differ from that expectation.\n",
        "\n",
        "----\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing ?\n",
        "- The **F-distribution** is a probability distribution used mainly to compare **variances** between two groups. It is **right-skewed** and only takes **positive values**.\n",
        "\n",
        "---\n",
        "\n",
        "### **When it is used in hypothesis testing:**\n",
        "\n",
        "1. **ANOVA (Analysis of Variance):**  \n",
        "   - To test if **three or more group means** are significantly different.\n",
        "\n",
        "2. **Test of Equal Variances:**  \n",
        "   - To compare the **variability** (variance) of two populations.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key features:**\n",
        "- Depends on **two degrees of freedom** (one for numerator, one for denominator)\n",
        "- The larger the F-value, the more likely you’ll reject the null hypothesis\n",
        "\n",
        "---\n",
        "\n",
        "### **In short:**  \n",
        "The **F-distribution** is used when testing hypotheses about **ratios of variances**, especially in **ANOVA** and **variance comparison** problems.\n",
        "\n",
        "----\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions ?\n",
        "- The **ANOVA (Analysis of Variance)** test is a statistical method used to determine if there are **significant differences between the means of three or more groups**.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Purpose:**\n",
        "To test the null hypothesis (**H₀**) that **all group means are equal**, against the alternative (**H₁**) that **at least one mean is different**.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **Assumptions of ANOVA:**\n",
        "\n",
        "1. **Independence**:  \n",
        "   Observations are independent within and across groups.\n",
        "\n",
        "2. **Normality**:  \n",
        "   The data in each group should be approximately normally distributed.\n",
        "\n",
        "3. **Homogeneity of variances** (equal variances):  \n",
        "   The variances across groups should be roughly equal.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 **In short:**  \n",
        "ANOVA tests if **group differences** are real or just due to **random variation**, and it's valid only if its key assumptions are met.\n",
        "\n",
        "----\n",
        "\n",
        "21.  What are the different types of ANOVA tests ?\n",
        "- There are **three main types of ANOVA** tests, each used for different experimental designs:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **One-Way ANOVA**\n",
        "- **Purpose:** Compares the means of **3 or more independent groups** based on **one factor** (independent variable).\n",
        "- **Example:** Comparing test scores across 3 different teaching methods.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Two-Way ANOVA**\n",
        "- **Purpose:** Compares the means across groups based on **two factors** and can test for:\n",
        "  - Main effects of each factor  \n",
        "  - Interaction effect between the two factors\n",
        "- **Example:** Studying the effect of **teaching method** and **study time** on test scores.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Repeated Measures ANOVA**\n",
        "- **Purpose:** Used when the **same subjects** are measured multiple times (within-subjects design).\n",
        "- **Example:** Measuring blood pressure in the same group of patients **before**, **during**, and **after** treatment.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔁 Summary:\n",
        "\n",
        "| Type                   | Factors | Groups | Repeated Measures? |\n",
        "|------------------------|---------|--------|---------------------|\n",
        "| **One-Way ANOVA**       | 1       | ≥3     | No                  |\n",
        "| **Two-Way ANOVA**       | 2       | ≥3     | No (can be extended)|\n",
        "| **Repeated Measures ANOVA** | 1+      | ≥3     | Yes                 |\n",
        "\n",
        "Each type helps analyze different kinds of data and research questions.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "22.  What is the F-test, and how does it relate to hypothesis testing ?\n",
        "- The **F-test** is a statistical test used to **compare variances** between two or more groups. It plays a key role in **hypothesis testing**, especially in tests involving multiple groups or models.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Purpose in Hypothesis Testing:**\n",
        "To test whether:\n",
        "- Two populations have **equal variances**  \n",
        "- Group means are **significantly different** (in **ANOVA**)  \n",
        "- A more complex model fits the data better than a simpler one (in **regression**)\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **Key Idea:**\n",
        "The **F-statistic** is the ratio of two variances:\n",
        "\\[\n",
        "F = \\frac{\\text{Variance between groups}}{\\text{Variance within groups}}\n",
        "\\]\n",
        "\n",
        "A **high F-value** suggests a significant difference between group means or variances.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔗 **Relation to Hypothesis Testing:**\n",
        "\n",
        "- **Null hypothesis (H₀):** No difference in variances or means (e.g., all group means are equal)\n",
        "- **Alternative hypothesis (H₁):** At least one variance or mean differs\n",
        "- Compare the F-value to a critical value from the **F-distribution**, or use the **p-value**\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 In short:  \n",
        "The **F-test** helps determine if differences between groups are **statistically significant**, and it's central to tests like **ANOVA** and **regression model comparisons**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hl9wK3oS0n9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "VWfjusjI5f6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results .\n",
        "\n",
        "- Sure! Here's a simple Python program that performs a one-sample Z-test to compare a sample mean to a known population mean, along with a basic interpretation of the results."
      ],
      "metadata": {
        "id": "ZawDkJKJ5nvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data\n",
        "sample_data = [52, 48, 51, 53, 47, 50, 49, 52, 46, 54]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Known population parameters\n",
        "population_mean = 50  # μ\n",
        "population_std = 2    # σ\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret result\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "YAqVzfzv7U--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python .\n",
        "- Simulates random sample data from a normal distribution\n",
        "- Performs a one-sample t-test\n",
        "- Calculates the p-value and interprets the result"
      ],
      "metadata": {
        "id": "LRTqxc7k7YMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Step 1: Simulate random data (e.g., test scores with mean ~72)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_data = np.random.normal(loc=72, scale=10, size=30)  # mean=72, std=10, n=30\n",
        "\n",
        "# Step 2: Set population mean to test against (e.g., μ = 70)\n",
        "population_mean = 70\n",
        "\n",
        "# Step 3: Perform one-sample t-test\n",
        "t_stat, p_value = ttest_1samp(sample_data, population_mean)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(f\"Sample Mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "hGqOcK5484lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean .\n",
        "\n",
        "# Python Code: One-Sample Z-Test"
      ],
      "metadata": {
        "id": "XWqUfg4b87n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data (can be replaced with any data)\n",
        "sample_data = [105, 98, 110, 102, 100, 108, 103, 97, 101, 106]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 100  # μ (hypothesized mean)\n",
        "population_std = 5     # σ (known population standard deviation)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Decision based on significance level\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "RGqYzue09KAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Perform a two-tailed Z-test using Python and visualize the decision region on a plot .\n",
        "- The normal distribution curve\n",
        "\n",
        "- The critical regions\n",
        "\n",
        "- The Z-score of your sample\n",
        "\n",
        "# Python Code: Two-Tailed Z-Test with Visualization"
      ],
      "metadata": {
        "id": "vyulJQZN9R8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample data\n",
        "sample_data = [105, 98, 110, 102, 100, 108, 103, 97, 101, 106]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 100   # μ\n",
        "population_std = 5      # σ (known)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Critical z-value for 95% confidence level (α = 0.05)\n",
        "z_critical = norm.ppf(1 - 0.05 / 2)\n",
        "\n",
        "# Display results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(\"Decision:\", \"Reject H₀\" if abs(z_score) > z_critical else \"Fail to reject H₀\")\n",
        "\n",
        "# ---- Visualization ----\n",
        "\n",
        "# Plot settings\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, label='Standard Normal Distribution', color='blue')\n",
        "\n",
        "# Shade critical regions\n",
        "plt.fill_between(x, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.3, label='Rejection Region (α = 0.05)')\n",
        "plt.axvline(z_score, color='green', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "# Annotations\n",
        "plt.title('Two-Tailed Z-Test with Rejection Regions')\n",
        "plt.xlabel('Z')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e2TJqFX_9gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing .\n",
        "- Calculates Type I (α) and Type II (β) errors\n",
        "\n",
        "- Visualizes both error regions under the null and alternative distributions\n",
        "\n",
        "- Helps you understand how sample size, effect size, and significance level affect the power of the test\n",
        "\n",
        "# Python Function to Calculate & Visualize Type I and Type II Errors:"
      ],
      "metadata": {
        "id": "qZ52BLt19n9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu0, mu1, sigma, n, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II error regions for a two-tailed Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - mu0: Mean under null hypothesis (H0)\n",
        "    - mu1: Mean under alternative hypothesis (H1)\n",
        "    - sigma: Population standard deviation\n",
        "    - n: Sample size\n",
        "    - alpha: Significance level (default 0.05)\n",
        "    \"\"\"\n",
        "\n",
        "    # Standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Z critical values for two-tailed test\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Critical sample means (bounds for rejection region under H0)\n",
        "    x_lower = mu0 - z_critical * se\n",
        "    x_upper = mu0 + z_critical * se\n",
        "\n",
        "    # Define x values for plotting\n",
        "    x = np.linspace(mu0 - 4*se, mu1 + 4*se, 1000)\n",
        "\n",
        "    # PDF for null and alternative distributions\n",
        "    y_null = norm.pdf(x, mu0, se)\n",
        "    y_alt = norm.pdf(x, mu1, se)\n",
        "\n",
        "    # Calculate Type II error (β): area under H1 curve in acceptance region\n",
        "    beta = norm.cdf(x_upper, mu1, se) - norm.cdf(x_lower, mu1, se)\n",
        "    power = 1 - beta\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y_null, label='H₀: μ = {}'.format(mu0), color='blue')\n",
        "    plt.plot(x, y_alt, label='H₁: μ = {}'.format(mu1), color='green')\n",
        "\n",
        "    # Shade Type I error regions (α)\n",
        "    plt.fill_between(x, y_null, where=(x <= x_lower) | (x >= x_upper), color='red', alpha=0.3, label='Type I Error (α)')\n",
        "\n",
        "    # Shade Type II error region (β)\n",
        "    plt.fill_between(x, y_alt, where=(x > x_lower) & (x < x_upper), color='orange', alpha=0.3, label='Type II Error (β)')\n",
        "\n",
        "    # Annotations\n",
        "    plt.axvline(x_lower, color='gray', linestyle='--')\n",
        "    plt.axvline(x_upper, color='gray', linestyle='--')\n",
        "\n",
        "    plt.title('Visualization of Type I and Type II Errors')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print error values\n",
        "    print(f\"Significance level (α): {alpha}\")\n",
        "    print(f\"Type II Error (β): {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - β): {power:.4f}\")\n"
      ],
      "metadata": {
        "id": "rpXOWXR692Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Usage:"
      ],
      "metadata": {
        "id": "6XS5rRKn968T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters:\n",
        "mu0 = 100     # Null hypothesis mean\n",
        "mu1 = 105     # Alternative hypothesis mean\n",
        "sigma = 10    # Population standard deviation\n",
        "n = 30        # Sample size\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "visualize_type1_type2_errors(mu0, mu1, sigma, n, alpha)\n"
      ],
      "metadata": {
        "id": "XyPhGR8U984e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results .\n",
        "\n",
        "#Python Code: Independent T-Test"
      ],
      "metadata": {
        "id": "DhWxEcu0-AwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data for two independent groups\n",
        "group1 = [88, 92, 85, 91, 87]\n",
        "group2 = [82, 79, 84, 76, 80]\n",
        "\n",
        "# Perform independent two-sample t-test (assumes equal variance by default)\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "# Output results\n",
        "print(\"Group 1 Mean:\", np.mean(group1))\n",
        "print(\"Group 2 Mean:\", np.mean(group2))\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference between groups).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n"
      ],
      "metadata": {
        "id": "tfaNX6apDTvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a paired sample T-test using Python and visualize the comparison results .\n",
        "\n",
        "#Python Code: Paired Sample T-Test with Visualization"
      ],
      "metadata": {
        "id": "ujDhL_D4DXF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Simulated paired data (e.g., scores before and after training)\n",
        "before = [72, 75, 78, 70, 69, 73, 74, 76]\n",
        "after  = [75, 78, 80, 73, 71, 77, 76, 79]\n",
        "\n",
        "# Perform paired t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Display results\n",
        "print(\"Before Mean:\", np.mean(before))\n",
        "print(\"After Mean:\", np.mean(after))\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis (significant difference between paired samples).\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n",
        "# ----- Visualization -----\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "x = np.arange(len(before))\n",
        "plt.plot(x, before, marker='o', label='Before', color='blue')\n",
        "plt.plot(x, after, marker='o', label='After', color='green')\n",
        "for i in range(len(before)):\n",
        "    plt.plot([x[i], x[i]], [before[i], after[i]], color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.title(\"Paired Sample Comparison (Before vs After)\")\n",
        "plt.xlabel(\"Subject\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uNPlEbtBDfzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Simulate data and perform both Z-test and T-test, then compare the results using Python .\n",
        "\n",
        "# Python Code: Simulate Data & Compare Z-test vs T-test"
      ],
      "metadata": {
        "id": "Jfm02LHiDlTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(0)  # For reproducibility\n",
        "sample_size = 25\n",
        "population_mean = 100\n",
        "population_std = 15  # Known population standard deviation (for Z-test)\n",
        "\n",
        "sample = np.random.normal(loc=102, scale=15, size=sample_size)  # Sample mean ~102\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "\n",
        "# Step 2: Perform Z-test (population std known)\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "z_p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: Perform T-test (sample std used)\n",
        "t_stat = (sample_mean - population_mean) / (sample_std / np.sqrt(sample_size))\n",
        "df = sample_size - 1\n",
        "t_p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "# Step 4: Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std:.2f}\\n\")\n",
        "\n",
        "print(\"Z-Test Results:\")\n",
        "print(f\"  Z-score: {z_score:.3f}\")\n",
        "print(f\"  P-value: {z_p_value:.4f}\")\n",
        "\n",
        "print(\"\\nT-Test Results:\")\n",
        "print(f\"  T-statistic: {t_stat:.3f}\")\n",
        "print(f\"  P-value: {t_p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\nInterpretation:\")\n",
        "if z_p_value < alpha:\n",
        "    print(\"  Z-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"  Z-test: Fail to reject the null hypothesis.\")\n",
        "\n",
        "if t_p_value < alpha:\n",
        "    print(\"  T-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"  T-test: Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "OAxlX-tpDvEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "\n",
        "#Python Function: Confidence Interval for Sample Mean"
      ],
      "metadata": {
        "id": "cdR8gY_xDy4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or array of sample observations\n",
        "    - confidence: confidence level (default = 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound)\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    df = n - 1  # degrees of freedom\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df)  # critical t value\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "    lower = mean - margin_of_error\n",
        "    upper = mean + margin_of_error\n",
        "\n",
        "    return lower, upper, mean, margin_of_error\n"
      ],
      "metadata": {
        "id": "3MxV_3AHEBal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Usage:"
      ],
      "metadata": {
        "id": "fm5_eSIrECWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "sample_data = [88, 90, 92, 85, 87, 91, 89]\n",
        "\n",
        "# Calculate 95% confidence interval\n",
        "lower, upper, mean, moe = confidence_interval(sample_data, confidence=0.95)\n",
        "\n",
        "print(f\"Sample Mean: {mean:.2f}\")\n",
        "print(f\"Margin of Error: {moe:.2f}\")\n",
        "print(f\"95% Confidence Interval: ({lower:.2f}, {upper:.2f})\")\n"
      ],
      "metadata": {
        "id": "OTkiFhveEEg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data .\n",
        "# Python Code: Calculate Margin of Error"
      ],
      "metadata": {
        "id": "KcBK6sQlEIHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def calculate_margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the margin of error for a sample mean using the T-distribution.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or array of sample values\n",
        "    - confidence: confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - margin of error\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    sample_std = np.std(data, ddof=1)\n",
        "    std_err = sample_std / np.sqrt(n)\n",
        "    df = n - 1\n",
        "\n",
        "    # Critical t-value\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "sample_data = [72, 75, 78, 70, 69, 73, 74, 76]\n",
        "\n",
        "confidence_level = 0.95\n",
        "moe = calculate_margin_of_error(sample_data, confidence=confidence_level)\n",
        "\n",
        "print(f\"Sample Size: {len(sample_data)}\")\n",
        "print(f\"Confidence Level: {int(confidence_level * 100)}%\")\n",
        "print(f\"Margin of Error: ±{moe:.2f}\")\n"
      ],
      "metadata": {
        "id": "TkjXM-LxERiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process .\n",
        "\n",
        "# Python Code: Bayesian Inference Example\n",
        "- We'll simulate a medical test scenario where:\n",
        "   - Disease affects 1% of the population\n",
        "\n",
        "   - Test is 95% accurate for positives and 90% accurate for negatives"
      ],
      "metadata": {
        "id": "Sr--cC8MEXJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_inference(prior, sensitivity, specificity):\n",
        "    \"\"\"\n",
        "    Computes the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - prior: P(Disease) → prior probability of the hypothesis\n",
        "    - sensitivity: P(Test+ | Disease) → true positive rate\n",
        "    - specificity: P(Test- | No Disease) → true negative rate\n",
        "\n",
        "    Returns:\n",
        "    - posterior: P(Disease | Test+)\n",
        "    \"\"\"\n",
        "\n",
        "    # Complement probabilities\n",
        "    p_disease = prior\n",
        "    p_no_disease = 1 - prior\n",
        "    p_test_given_disease = sensitivity\n",
        "    p_test_given_no_disease = 1 - specificity\n",
        "\n",
        "    # Bayes' Theorem\n",
        "    numerator = p_test_given_disease * p_disease\n",
        "    denominator = (p_test_given_disease * p_disease) + (p_test_given_no_disease * p_no_disease)\n",
        "\n",
        "    posterior = numerator / denominator\n",
        "    return posterior\n",
        "\n",
        "# Example: Disease test\n",
        "prior = 0.01          # 1% of people have the disease\n",
        "sensitivity = 0.95    # Test correctly identifies 95% of cases\n",
        "specificity = 0.90    # Test correctly identifies 90% of non-cases\n",
        "\n",
        "posterior = bayesian_inference(prior, sensitivity, specificity)\n",
        "print(f\"Probability of having the disease given a positive test result: {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "WLJOcGPGE11F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output Example:"
      ],
      "metadata": {
        "id": "Iqkvox8gE6wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Probability of having the disease given a positive test result: 0.0876\n"
      ],
      "metadata": {
        "id": "5NcTi9-TE8Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only ~8.76% chance the person actually has the disease, even after a positive test"
      ],
      "metadata": {
        "id": "h5friL01E9_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform a Chi-square test for independence between two categorical variables in Python .\n",
        "\n",
        "#Steps for Chi-Square Test for Independence:\n",
        "- Create a contingency table.\n",
        "- Use scipy.stats.chi2_contingency() to calculate:\n",
        "   - Chi-square statistic\n",
        "\n",
        "   - p-value\n",
        "\n",
        "   - degrees of freedom\n",
        "\n",
        "   - expected frequencies\n",
        "\n",
        "- Interpret the result.\n",
        "\n",
        "\n",
        "#Python Code Example: Chi-Square Test for Independence\n"
      ],
      "metadata": {
        "id": "lhGTC0ftFDoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Create a contingency table (e.g., Gender vs Preference)\n",
        "# Rows = Gender (Male, Female), Columns = Preference (A, B)\n",
        "data = [[30, 10],   # Male\n",
        "        [20, 40]]   # Female\n",
        "\n",
        "table = pd.DataFrame(data, columns=['Preference_A', 'Preference_B'], index=['Male', 'Female'])\n",
        "\n",
        "# Step 2: Perform the Chi-square test\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(table)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(\"Contingency Table:\")\n",
        "print(table)\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(pd.DataFrame(expected, columns=table.columns, index=table.index))\n",
        "\n",
        "print(f\"\\nChi-square Statistic: {chi2_stat:.3f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. Variables are dependent (associated).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant association.\")\n"
      ],
      "metadata": {
        "id": "0hrxhUy4FiOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Output:"
      ],
      "metadata": {
        "id": "QHfom_U3FmbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Chi-square Statistic: 16.071\n",
        "Degrees of Freedom: 1\n",
        "P-value: 0.0001\n",
        "Conclusion: Reject the null hypothesis. Variables are dependent (associated).\n"
      ],
      "metadata": {
        "id": "yl2ZLdYpFoGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data.\n",
        "\n",
        "#Python Code: Calculate Expected Frequencies"
      ],
      "metadata": {
        "id": "BEnk9676FrQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Create observed data (contingency table)\n",
        "# Example: Gender (Male, Female) vs Preference (A, B)\n",
        "observed = np.array([[30, 10],   # Male\n",
        "                     [20, 40]])  # Female\n",
        "\n",
        "# Convert to DataFrame for better display\n",
        "table = pd.DataFrame(observed, columns=[\"Preference_A\", \"Preference_B\"], index=[\"Male\", \"Female\"])\n",
        "\n",
        "# Step 2: Use chi2_contingency to get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
        "\n",
        "# Step 3: Display results\n",
        "print(\"Observed Frequencies:\")\n",
        "print(table)\n",
        "\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "expected_df = pd.DataFrame(expected, columns=table.columns, index=table.index)\n",
        "print(expected_df.round(2))\n",
        "\n"
      ],
      "metadata": {
        "id": "Tls4W0SjF1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How Expected Frequencies Are Calculated:\n",
        "Each expected frequency is calculated as:\n",
        "\n",
        "𝐸\n",
        "𝑖\n",
        "𝑗\n",
        "=\n",
        "(\n",
        "𝑅\n",
        "𝑜\n",
        "𝑤\n",
        "\n",
        "𝑇\n",
        "𝑜\n",
        "𝑡\n",
        "𝑎\n",
        "𝑙\n",
        "𝑖\n",
        "×\n",
        "𝐶\n",
        "𝑜\n",
        "𝑙\n",
        "𝑢\n",
        "𝑚\n",
        "𝑛\n",
        "\n",
        "𝑇\n",
        "𝑜\n",
        "𝑡\n",
        "𝑎\n",
        "𝑙\n",
        "𝑗\n",
        ")\n",
        "𝐺\n",
        "𝑟\n",
        "𝑎\n",
        "𝑛\n",
        "𝑑\n",
        "\n",
        "𝑇\n",
        "𝑜\n",
        "𝑡\n",
        "𝑎\n",
        "𝑙\n",
        "E\n",
        "ij\n",
        "​\n",
        " =\n",
        "Grand Total\n",
        "(Row Total\n",
        "i\n",
        "​\n",
        " ×Column Total\n",
        "j\n",
        "​\n",
        " )\n",
        "​\n"
      ],
      "metadata": {
        "id": "AfHOhoH2GFVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example Output:"
      ],
      "metadata": {
        "id": "RZbZO-JdGNz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Observed Frequencies:\n",
        "        Preference_A  Preference_B\n",
        "Male              30            10\n",
        "Female            20            40\n",
        "\n",
        "Expected Frequencies:\n",
        "        Preference_A  Preference_B\n",
        "Male            20.0          20.0\n",
        "Female          30.0          30.0\n"
      ],
      "metadata": {
        "id": "9Qur_FmjGOzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution .\n",
        "\n",
        "#Steps for Goodness-of-Fit Test:\n",
        "- 1. Define observed frequencies (from your data).\n",
        "\n",
        "- 2. Define expected frequencies (based on a theoretical distribution or assumption).\n",
        "\n",
        "- 3. Use scipy.stats.chisquare() to perform the test.\n",
        "\n",
        "- 4. Interpret the result.\n",
        "\n",
        "# Python Code: Chi-square Goodness-of-Fit Test"
      ],
      "metadata": {
        "id": "zjLCEJt8GUCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Step 1: Observed data (e.g., categories: A, B, C)\n",
        "observed = np.array([25, 30, 45])\n",
        "\n",
        "# Step 2: Expected distribution (e.g., uniform or specific ratio)\n",
        "# Example: Expected proportions are equal (uniform distribution)\n",
        "expected = np.array([33.33, 33.33, 33.33])  # Or use expected = np.full(3, np.sum(observed) / 3)\n",
        "\n",
        "# Step 3: Perform the Chi-square goodness-of-fit test\n",
        "chi_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(\"Observed Frequencies:\", observed)\n",
        "print(\"Expected Frequencies:\", expected.round(2))\n",
        "print(f\"\\nChi-square Statistic: {chi_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The data does not fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. The data fits the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "gPnpAJwDGnVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics .\n",
        "\n",
        "#Python Script: Simulate and Visualize Chi-Square Distribution"
      ],
      "metadata": {
        "id": "IC6zFrhFGtJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Set up degrees of freedom to visualize\n",
        "dfs = [1, 2, 5, 10, 20]\n",
        "\n",
        "# Create a range of x values\n",
        "x = np.linspace(0, 40, 500)\n",
        "\n",
        "# Plot the Chi-square distribution for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "for df in dfs:\n",
        "    y = chi2.pdf(x, df)\n",
        "    plt.plot(x, y, label=f'df = {df}')\n",
        "\n",
        "# Plot settings\n",
        "plt.title('Chi-Square Distribution for Various Degrees of Freedom')\n",
        "plt.xlabel('Chi-square value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f8KGPAYKG1bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  Implement an F-test using Python to compare the variances of two random samples .\n",
        "\n",
        "# Python Code: F-Test for Equality of Variances"
      ],
      "metadata": {
        "id": "Q8l10cuxG5CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "def f_test(sample1, sample2):\n",
        "    # Sample sizes\n",
        "    n1 = len(sample1)\n",
        "    n2 = len(sample2)\n",
        "\n",
        "    # Sample variances\n",
        "    var1 = np.var(sample1, ddof=1)\n",
        "    var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "    # Ensure F is the ratio of the larger to smaller variance\n",
        "    if var1 > var2:\n",
        "        F = var1 / var2\n",
        "        df1, df2 = n1 - 1, n2 - 1\n",
        "    else:\n",
        "        F = var2 / var1\n",
        "        df1, df2 = n2 - 1, n1 - 1\n",
        "\n",
        "    # p-value (two-tailed)\n",
        "    p_value = 2 * min(f.cdf(F, df1, df2), 1 - f.cdf(F, df1, df2))\n",
        "\n",
        "    return F, p_value, df1, df2\n",
        "\n",
        "# 🔢 Example: Simulate two random samples\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "sample2 = np.random.normal(loc=50, scale=20, size=30)\n",
        "\n",
        "# Perform F-test\n",
        "F_stat, p_val, df1, df2 = f_test(sample1, sample2)\n",
        "\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: {df1}, {df2}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "\n",
        "# Interpret\n",
        "alpha = 0.\n"
      ],
      "metadata": {
        "id": "_FT_QeMCHJVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "interpret the results.\n",
        "\n",
        "#Python Code: One-Way ANOVA"
      ],
      "metadata": {
        "id": "yu9SaJrBHNXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate data for multiple groups\n",
        "np.random.seed(42)\n",
        "\n",
        "group1 = np.random.normal(loc=50, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=52, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=55, scale=5, size=30)\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference between group means.\")\n"
      ],
      "metadata": {
        "id": "nGhiYBicHYeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Output:"
      ],
      "metadata": {
        "id": "-Id8GwkBHfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANOVA Results:\n",
        "F-statistic: 8.1452\n",
        "P-value: 0.0006\n",
        "Conclusion: Reject the null hypothesis. At least one group mean is significantly different.\n"
      ],
      "metadata": {
        "id": "QHQ2RtW2HgWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results .\n",
        "\n",
        "#One-Way ANOVA with Plot (Boxplot)"
      ],
      "metadata": {
        "id": "K57Tk_SEHlq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate sample data for 3 groups\n",
        "np.random.seed(1)\n",
        "group_A = np.random.normal(loc=60, scale=5, size=30)\n",
        "group_B = np.random.normal(loc=65, scale=5, size=30)\n",
        "group_C = np.random.normal(loc=70, scale=5, size=30)\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group_A, group_B, group_C)\n",
        "\n",
        "# Step 3: Print ANOVA results\n",
        "print(\"ANOVA Test Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis — at least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis — no significant difference in means.\")\n",
        "\n",
        "# Step 4: Prepare data for plotting\n",
        "df = pd.DataFrame({\n",
        "    'Scores': np.concatenate([group_A, group_B, group_C]),\n",
        "    'Group': ['A'] * len(group_A) + ['B'] * len(group_B) + ['C'] * len(group_C)\n",
        "})\n",
        "\n",
        "# Step 5: Plot the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns\n"
      ],
      "metadata": {
        "id": "CNFyaYZSHsZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA .\n",
        "\n",
        "#Python Function: Check ANOVA Assumptions"
      ],
      "metadata": {
        "id": "H6gJY9k-H0_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(data, group_col, value_col, plot=True):\n",
        "    grouped = data.groupby(group_col)[value_col]\n",
        "    results = {}\n",
        "\n",
        "    print(\"---- Normality (Shapiro-Wilk Test) ----\")\n",
        "    for name, group in grouped:\n",
        "        stat, p = shapiro(group)\n",
        "        results[name] = {'Shapiro-Wilk p-value': p}\n",
        "        print(f\"Group {name}: p = {p:.4f} {'✅' if p > 0.05 else '❌'}\")\n",
        "\n",
        "    print(\"\\n---- Homogeneity of Variances (Levene’s Test) ----\")\n",
        "    groups = [group for name, group in grouped]\n",
        "    stat, p = levene(*groups)\n",
        "    results['Levene’s Test'] = {'p-value': p}\n",
        "    print(f\"Levene’s Test: p = {p:.4f} {'✅' if p > 0.05 else '❌'}\")\n",
        "\n",
        "    print(\"\\n✅ Independence assumption should be based on study design (not tested here).\")\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 5))\n"
      ],
      "metadata": {
        "id": "OxRHAGc7H9Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How to Use It:"
      ],
      "metadata": {
        "id": "w_PGLTY4IAg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate example data\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame({\n",
        "    'Group': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
        "    'Score': np.concatenate([\n",
        "        np.random.normal(60, 5, 30),\n",
        "        np.random.normal(62, 5, 30),\n",
        "        np.random.normal(65, 5, 30)\n",
        "    ])\n",
        "})\n",
        "\n",
        "# Run assumption checks\n",
        "check_anova_assumptions(df, group_col='Group', value_col='Score')\n"
      ],
      "metadata": {
        "id": "NXoIL8Y0IDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the\n",
        "results .\n",
        "\n",
        "#Two-Way ANOVA with Interaction in Python"
      ],
      "metadata": {
        "id": "h5G8WfswIH1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(1)\n",
        "df = pd.DataFrame({\n",
        "    'FactorA': np.repeat(['Low', 'High'], 30),\n",
        "    'FactorB': np.tile(np.repeat(['X', 'Y', 'Z'], 10), 2),\n",
        "    'Score': np.random.normal(loc=50, scale=5, size=60)\n",
        "})\n",
        "# Introduce interaction effect\n",
        "df.loc[(df['FactorA'] == 'High') & (df['FactorB'] == 'Z'), 'Score'] += 10\n",
        "\n",
        "# Two-way ANOVA with interaction\n",
        "model = ols('Score ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.pointplot(x='FactorB', y='Score', hue='FactorA', data=df, capsize=.1, palette='pastel', dodge=True)\n",
        "plt.title('Interaction Plot: FactorA vs FactorB')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wK0yDeYeIURT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing.\n",
        "\n",
        "#Python Program: Visualize F-Distribution"
      ],
      "metadata": {
        "id": "wDBRt85oIX5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Define degrees of freedom\n",
        "df1, df2 = 5, 20\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "# Plot F-distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})', color='skyblue')\n",
        "plt.fill_between(x, y, where=(x > f.ppf(0.95, df1, df2)), color='red', alpha=0.3, label='Critical region (_\n"
      ],
      "metadata": {
        "id": "2xY2mu1NIoVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.  Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means .\n",
        "\n",
        "#One-Way ANOVA with Boxplot in Python\n",
        "\n"
      ],
      "metadata": {
        "id": "diCL53ELIuba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate data for 3 groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=60, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=65, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=70, scale=5, size=30)\n",
        "\n",
        "# Step 2: Combine data into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Score': np.concatenate([group1, group2, group3]),\n",
        "    'Group': ['Group 1'] * 30 + ['Group 2'] * 30 + ['Group 3'] * 30\n",
        "})\n",
        "\n",
        "# Step 3: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"One-Way ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4_\n"
      ],
      "metadata": {
        "id": "HqRRH9j8I3Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.  Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means .\n",
        "\n",
        "# Python: Simulate & Test Mean"
      ],
      "metadata": {
        "id": "Y0xl-hECI9T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Simulate data from N(μ=50, σ=5)\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=5, size=30)\n",
        "\n",
        "# Perform one-sample t-test against population mean = 52\n",
        "t_stat, p_value = ttest_1samp(data, popmean=52)\n",
        "\n",
        "print(\"One-Sample T-Test Results:\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The sample mean is significantly different from 52.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference from 52.\")\n"
      ],
      "metadata": {
        "id": "TCOyPK5vI-o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results .\n",
        "\n",
        "#Python Code: Variance Test using Chi-Square"
      ],
      "metadata": {
        "id": "erU-GxqwJKCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Simulate sample data\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=50, scale=5, size=30)  # σ = 5 ⇒ variance = 25\n",
        "\n",
        "# Hypothesized population variance (σ₀²)\n",
        "sigma_sq_0 = 20\n",
        "\n",
        "# Calculate sample variance\n",
        "n = len(sample)\n",
        "sample_var = np.var(sample, ddof=1)  # sample variance with Bessel's correction\n",
        "\n",
        "# Chi-square test statistic\n",
        "chi2_stat = (n - 1) * sample_var / sigma_sq_0\n",
        "\n",
        "# Degrees of freedom\n",
        "df = n - 1\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Critical\n"
      ],
      "metadata": {
        "id": "fLGQoFEQJTGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.  Write a Python script to perform a Z-test for comparing proportions between two datasets or groups .\n",
        "\n",
        "#Z-Test for Two Proportions – Python Script"
      ],
      "metadata": {
        "id": "dwmDPLD9Jbh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Example data: Group A and Group B\n",
        "successes = [45, 30]       # Number of successes in each group\n",
        "n_obs = [100, 100]         # Total observations in each group\n",
        "\n",
        "# Perform Z-test for proportions\n",
        "z_stat, p_value = proportions_ztest(successes, n_obs)\n",
        "\n",
        "print(\"Z-Test for Two Proportions:\")\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference in proportions.\")\n"
      ],
      "metadata": {
        "id": "SOuW3OIwJi9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.  Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results .\n",
        "\n",
        "#Python Code: F-Test for Variance Comparison\n"
      ],
      "metadata": {
        "id": "L5SNVnfjJl8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Step 1: Simulate two datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=10, size=30)  # variance ~ 100\n",
        "data2 = np.random.normal(loc=55, scale=7, size=30)   # variance ~ 49\n",
        "\n",
        "# Step 2: Calculate sample variances\n",
        "var1 = np.var(data1, ddof=1)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "\n",
        "# Step 3: Perform F-test\n",
        "f_stat = var1 / var2\n",
        "df1 = len(data1) - 1\n",
        "df2 = len(data2) - 1\n",
        "alpha = 0.05\n",
        "\n",
        "# Critical values for two-tailed test\n",
        "f_critical_low = f.ppf(alpha / 2, df1, df2)\n",
        "f_critical_high = f.ppf(1 - alpha / 2, df1, df2)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"F-Test to Compare Variances:\")\n",
        "print(f\"Sample variance 1: {var1:.2f}\")\n",
        "print(f\"Sample variance 2: {var2:.2f}\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"Critical range: ({f_critical_low:.4f}, {f_critical_high:.4f})\")\n",
        "\n",
        "# Step 5: Interpret result\n",
        "if f_stat < f_critical_low or f_stat > f_critical_high:\n",
        "    print(\"Conclusion: Reject null hypothesis – variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject null hypothesis – no significant difference in variances.\")\n",
        "\n",
        "# Step 6: Visualize F-distribution and test result\n",
        "x = np.linspace(0.1, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label='F-distribution', color='skyblue')\n",
        "plt.axvline(f_stat, color='green', linestyle='--', label=f'F-stat = {f_stat:.2f}')\n",
        "plt.axvline(f_critical_low, color='red', linestyle='--', label='Critical values')\n",
        "plt.axvline(f_critical_high, color='red', linestyle='--')\n",
        "\n",
        "plt.fill_between(x, y, where=(x < f_critical_low) | (x > f_critical_high), color='red', alpha=0.2)\n",
        "plt.title('F-Distribution and Critical Regions')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--',\n"
      ],
      "metadata": {
        "id": "WI80GwiEJw4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "\n",
        "#Python Code: Chi-square Goodness-of-Fit Test"
      ],
      "metadata": {
        "id": "_X_fYuoNJ2tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate observed data (e.g., frequencies of 4 categories)\n",
        "np.random.seed(42)\n",
        "observed = np.random.multinomial(100, [0.3, 0.2, 0.3, 0.2])  # Not perfectly uniform\n",
        "\n",
        "# Step 2: Define expected frequencies (e.g., uniform distribution)\n",
        "expected = [25, 25, 25, 25]  # Expecting equal frequency in 4 categories\n",
        "\n",
        "# Step 3: Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Print results\n",
        "print(\"Chi-square Goodness-of-Fit Test:\")\n",
        "print(f\"Observed: {observed}\")\n",
        "print(f\"Expected: {expected}\")\n",
        "print(f\"Chi2 Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. Observed data does not fit expected distribution.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. Observed data fits the expected distribution.\")\n",
        "\n",
        "# Step 6: Visualization\n",
        "categories = ['A', 'B', 'C', 'D']\n",
        "x = np.arange(len(categories))\n",
        "plt.bar(x - 0.2, observed, width=0.4, label='Observed', color='skyblue')\n",
        "plt.bar(x + 0.2, expected, width=0.4, label='Expected', color='orange')\n",
        "plt.xticks(x, categories)\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Observed vs Expected Frequencies')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yucd1jDRJ_4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}